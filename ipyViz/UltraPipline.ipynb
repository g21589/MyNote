{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-model with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T15:08:10.219104Z",
     "start_time": "2019-02-14T15:07:56.713442Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T02:23:12.214508Z",
     "start_time": "2019-02-04T02:23:12.206531Z"
    }
   },
   "outputs": [],
   "source": [
    "class EstimatorSelectionHelper(BaseEstimator):\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for '%s'.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator'  : key,\n",
    "                 'min_score'  : min(scores),\n",
    "                 'max_score'  : max(scores),\n",
    "                 'mean_score' : np.mean(scores),\n",
    "                 'std_score'  : np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()\n",
    "X_cancer = breast_cancer.data\n",
    "y_cancer = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T02:25:38.912674Z",
     "start_time": "2019-02-04T02:25:38.909682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "print(X_cancer.shape)\n",
    "print(y_cancer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T01:40:15.060798Z",
     "start_time": "2019-02-04T01:40:15.045839Z"
    }
   },
   "outputs": [],
   "source": [
    "models1 = {\n",
    "    'ExtraTreesClassifier'       : ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier'     : RandomForestClassifier(),\n",
    "    'AdaBoostClassifier'         : AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier' : GradientBoostingClassifier(),\n",
    "    'SVC'                        : SVC()\n",
    "}\n",
    "\n",
    "params1 = {\n",
    "    'ExtraTreesClassifier': { 'n_estimators': [16, 32] },\n",
    "    'RandomForestClassifier': { 'n_estimators': [16, 32] },\n",
    "    'AdaBoostClassifier': { 'n_estimators': [16, 32] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T02:23:23.724619Z",
     "start_time": "2019-02-04T02:23:16.215700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for 'ExtraTreesClassifier'.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for 'RandomForestClassifier'.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Running GridSearchCV for 'AdaBoostClassifier'.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for 'GradientBoostingClassifier'.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Running GridSearchCV for 'SVC'.\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  18 out of  18 | elapsed:    6.1s finished\n"
     ]
    }
   ],
   "source": [
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "helper1.fit(X_cancer, y_cancer, scoring='f1', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T02:14:57.447694Z",
     "start_time": "2019-02-04T02:14:57.422779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "GradientBoostingClassifier\n",
      "SVC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.962343</td>\n",
       "      <td>0.974907</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.0123335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.953975</td>\n",
       "      <td>0.969303</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.0120697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.962343</td>\n",
       "      <td>0.972047</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.95279</td>\n",
       "      <td>0.966463</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.0126727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.960877</td>\n",
       "      <td>0.979253</td>\n",
       "      <td>0.0132893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>0.962261</td>\n",
       "      <td>0.979079</td>\n",
       "      <td>0.0180396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.965102</td>\n",
       "      <td>0.979079</td>\n",
       "      <td>0.0117137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.953975</td>\n",
       "      <td>0.963965</td>\n",
       "      <td>0.978903</td>\n",
       "      <td>0.0107616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.965184</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.0114539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.953854</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.0178034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.961108</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.0102354</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.963747</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.00250593</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.945366</td>\n",
       "      <td>0.955466</td>\n",
       "      <td>0.00815896</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.946564</td>\n",
       "      <td>0.954733</td>\n",
       "      <td>0.00843008</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.926407</td>\n",
       "      <td>0.936624</td>\n",
       "      <td>0.94958</td>\n",
       "      <td>0.00965657</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.929334</td>\n",
       "      <td>0.940678</td>\n",
       "      <td>0.00907845</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     estimator min_score mean_score max_score   std_score  \\\n",
       "5           AdaBoostClassifier  0.962343   0.974907  0.991667   0.0123335   \n",
       "0         ExtraTreesClassifier  0.953975   0.969303  0.983471   0.0120697   \n",
       "2       RandomForestClassifier  0.962343   0.972047  0.983333    0.008642   \n",
       "4           AdaBoostClassifier   0.95279   0.966463  0.983333   0.0126727   \n",
       "6   GradientBoostingClassifier  0.948276   0.960877  0.979253   0.0132893   \n",
       "3       RandomForestClassifier  0.937238   0.962261  0.979079   0.0180396   \n",
       "9   GradientBoostingClassifier  0.950413   0.965102  0.979079   0.0117137   \n",
       "1         ExtraTreesClassifier  0.953975   0.963965  0.978903   0.0107616   \n",
       "7   GradientBoostingClassifier  0.949153   0.965184  0.975207   0.0114539   \n",
       "8   GradientBoostingClassifier  0.931624   0.953854  0.975207   0.0178034   \n",
       "10                         SVC   0.95122   0.961108  0.975207   0.0102354   \n",
       "11                         SVC  0.961373   0.963747  0.967213  0.00250593   \n",
       "15                         SVC  0.935484   0.945366  0.955466  0.00815896   \n",
       "13                         SVC  0.934959   0.946564  0.954733  0.00843008   \n",
       "12                         SVC  0.926407   0.936624   0.94958  0.00965657   \n",
       "14                         SVC  0.918455   0.929334  0.940678  0.00907845   \n",
       "\n",
       "      C   gamma  kernel learning_rate n_estimators  \n",
       "5   NaN     NaN     NaN           NaN           32  \n",
       "0   NaN     NaN     NaN           NaN           16  \n",
       "2   NaN     NaN     NaN           NaN           16  \n",
       "4   NaN     NaN     NaN           NaN           16  \n",
       "6   NaN     NaN     NaN           0.8           16  \n",
       "3   NaN     NaN     NaN           NaN           32  \n",
       "9   NaN     NaN     NaN             1           32  \n",
       "1   NaN     NaN     NaN           NaN           32  \n",
       "7   NaN     NaN     NaN           0.8           32  \n",
       "8   NaN     NaN     NaN             1           16  \n",
       "10    1     NaN  linear           NaN          NaN  \n",
       "11   10     NaN  linear           NaN          NaN  \n",
       "15   10  0.0001     rbf           NaN          NaN  \n",
       "13    1  0.0001     rbf           NaN          NaN  \n",
       "12    1   0.001     rbf           NaN          NaN  \n",
       "14   10   0.001     rbf           NaN          NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper1.score_summary(sort_by='max_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T02:52:50.764886Z",
     "start_time": "2019-02-04T02:52:40.581483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for 'ExtraTreesClassifier'.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   6 out of   6 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for 'RandomForestClassifier'.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Running GridSearchCV for 'AdaBoostClassifier'.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Running GridSearchCV for 'GradientBoostingClassifier'.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  12 out of  12 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for 'SVC'.\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  18 out of  18 | elapsed:    8.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('selector', EstimatorSelectionHelper(models={'ExtraTreesClassifier': ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_dep...kernel': ['linear'], 'C': [1, 10]}, {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]}]}))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "\n",
    "flow = Pipeline([\n",
    "    ('pca', pca),\n",
    "    ('selector', helper1),\n",
    "])\n",
    "\n",
    "flow.fit(X_cancer, y_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T02:39:48.956140Z",
     "start_time": "2019-02-04T02:39:48.935180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "GradientBoostingClassifier\n",
      "SVC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.942105</td>\n",
       "      <td>0.959603</td>\n",
       "      <td>0.973545</td>\n",
       "      <td>0.0130791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.940295</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.0261978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.94205</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.0267824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.941799</td>\n",
       "      <td>0.949021</td>\n",
       "      <td>0.963158</td>\n",
       "      <td>0.00999729</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.942105</td>\n",
       "      <td>0.956075</td>\n",
       "      <td>0.963158</td>\n",
       "      <td>0.00987868</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.924459</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>0.0364998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.889474</td>\n",
       "      <td>0.93325</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>0.0310361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.935004</td>\n",
       "      <td>0.952632</td>\n",
       "      <td>0.0247519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.933241</td>\n",
       "      <td>0.952632</td>\n",
       "      <td>0.0236132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.93325</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.889474</td>\n",
       "      <td>0.927977</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.0272264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.929713</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.0178482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.931468</td>\n",
       "      <td>0.942105</td>\n",
       "      <td>0.0113191</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.929704</td>\n",
       "      <td>0.942105</td>\n",
       "      <td>0.0107965</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.910053</td>\n",
       "      <td>0.920895</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.0115171</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.899471</td>\n",
       "      <td>0.912104</td>\n",
       "      <td>0.926316</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     estimator min_score mean_score max_score   std_score  \\\n",
       "1         ExtraTreesClassifier  0.942105   0.959603  0.973545   0.0130791   \n",
       "4           AdaBoostClassifier  0.905263   0.940295  0.968254   0.0261978   \n",
       "5           AdaBoostClassifier  0.905263    0.94205  0.968254   0.0267824   \n",
       "10                         SVC  0.941799   0.949021  0.963158  0.00999729   \n",
       "11                         SVC  0.942105   0.956075  0.963158  0.00987868   \n",
       "6   GradientBoostingClassifier  0.873684   0.924459  0.957895   0.0364998   \n",
       "9   GradientBoostingClassifier  0.889474    0.93325  0.957895   0.0310361   \n",
       "7   GradientBoostingClassifier       0.9   0.935004  0.952632   0.0247519   \n",
       "8   GradientBoostingClassifier       0.9   0.933241  0.952632   0.0236132   \n",
       "0         ExtraTreesClassifier       0.9    0.93325  0.952381      0.0236   \n",
       "2       RandomForestClassifier  0.889474   0.927977  0.947368   0.0272264   \n",
       "3       RandomForestClassifier  0.905263   0.929713  0.947368   0.0178482   \n",
       "13                         SVC  0.915789   0.931468  0.942105   0.0113191   \n",
       "15                         SVC  0.915789   0.929704  0.942105   0.0107965   \n",
       "12                         SVC  0.910053   0.920895  0.936842   0.0115171   \n",
       "14                         SVC  0.899471   0.912104  0.926316    0.011016   \n",
       "\n",
       "      C   gamma  kernel learning_rate n_estimators  \n",
       "1   NaN     NaN     NaN           NaN           32  \n",
       "4   NaN     NaN     NaN           NaN           16  \n",
       "5   NaN     NaN     NaN           NaN           32  \n",
       "10    1     NaN  linear           NaN          NaN  \n",
       "11   10     NaN  linear           NaN          NaN  \n",
       "6   NaN     NaN     NaN           0.8           16  \n",
       "9   NaN     NaN     NaN             1           32  \n",
       "7   NaN     NaN     NaN           0.8           32  \n",
       "8   NaN     NaN     NaN             1           16  \n",
       "0   NaN     NaN     NaN           NaN           16  \n",
       "2   NaN     NaN     NaN           NaN           16  \n",
       "3   NaN     NaN     NaN           NaN           32  \n",
       "13    1  0.0001     rbf           NaN          NaN  \n",
       "15   10  0.0001     rbf           NaN          NaN  \n",
       "12    1   0.001     rbf           NaN          NaN  \n",
       "14   10   0.001     rbf           NaN          NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper1.score_summary(sort_by='max_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipelinehelper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## boston house-prices (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T16:03:59.968527Z",
     "start_time": "2019-02-14T16:03:59.959551Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn import datasets\n",
    "from pipelinehelper import PipelineHelper\n",
    "\n",
    "X, y = datasets.load_boston(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T16:07:21.647072Z",
     "start_time": "2019-02-14T16:07:21.567286Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2762862e710>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T16:17:15.843858Z",
     "start_time": "2019-02-14T16:17:13.942965Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__selected_model': ('rf', {'n_estimators': 10}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': False})}\n",
      "-27.41712608695652\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:    1.8s finished\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaler', PipelineHelper([\n",
    "        ('std', StandardScaler()),\n",
    "        ('max', MaxAbsScaler()),\n",
    "    ], include_bypass=True)), # this will produce one setting without scaler\n",
    "    ('regressor', PipelineHelper([\n",
    "        ('rf', RandomForestRegressor()),\n",
    "        ('ada', AdaBoostRegressor()),\n",
    "        ('gb', GradientBoostingRegressor()),\n",
    "    ])),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'scaler__selected_model': pipe.named_steps['scaler'].generate({\n",
    "        'std__with_mean': [True, False],\n",
    "        'std__with_std': [True, False],\n",
    "        # no params for 'max' leads to using standard params\n",
    "    }),\n",
    "    'regressor__selected_model': pipe.named_steps['regressor'].generate({\n",
    "\n",
    "        'rf__n_estimators': [10, 20],\n",
    "\n",
    "        'ada__n_estimators': [10, 20],\n",
    "        \n",
    "        'gb__n_estimators': [10, 20],\n",
    "        #'gb__criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "        #'gb__max_features': ['auto', 'sqrt', None],\n",
    "\n",
    "    })\n",
    "}\n",
    "grid = GridSearchCV(pipe, params, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1, return_train_score=True)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T16:17:30.185326Z",
     "start_time": "2019-02-14T16:17:30.112491Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_regressor__selected_model</th>\n",
       "      <th>param_scaler__selected_model</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-27.417126</td>\n",
       "      <td>-2.121529</td>\n",
       "      <td>(rf, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.189778</td>\n",
       "      <td>-2.794439</td>\n",
       "      <td>-27.574961</td>\n",
       "      <td>-2.174025</td>\n",
       "      <td>-44.588243</td>\n",
       "      <td>-1.396122</td>\n",
       "      <td>7.366596e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.036558</td>\n",
       "      <td>0.572066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.026035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.873305</td>\n",
       "      <td>-1.781403</td>\n",
       "      <td>(rf, {'n_estimators': 10})</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.302500</td>\n",
       "      <td>-2.424125</td>\n",
       "      <td>-30.776126</td>\n",
       "      <td>-1.572546</td>\n",
       "      <td>-47.652407</td>\n",
       "      <td>-1.347537</td>\n",
       "      <td>7.363785e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.112965</td>\n",
       "      <td>0.463664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.046865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.903251</td>\n",
       "      <td>-1.469765</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>3</td>\n",
       "      <td>-9.290991</td>\n",
       "      <td>-1.707056</td>\n",
       "      <td>-32.118273</td>\n",
       "      <td>-1.590325</td>\n",
       "      <td>-45.398091</td>\n",
       "      <td>-1.111915</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.908186</td>\n",
       "      <td>0.257487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.057278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.773320</td>\n",
       "      <td>-1.574397</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>4</td>\n",
       "      <td>-12.202377</td>\n",
       "      <td>-2.009331</td>\n",
       "      <td>-30.714959</td>\n",
       "      <td>-1.480838</td>\n",
       "      <td>-46.501607</td>\n",
       "      <td>-1.233023</td>\n",
       "      <td>1.472813e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.011497</td>\n",
       "      <td>0.323757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.046864</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>-29.839364</td>\n",
       "      <td>-1.538114</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.834350</td>\n",
       "      <td>-1.927962</td>\n",
       "      <td>-30.986804</td>\n",
       "      <td>-1.502737</td>\n",
       "      <td>-47.803233</td>\n",
       "      <td>-1.183645</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>15.106827</td>\n",
       "      <td>0.304894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.052072</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>-29.944476</td>\n",
       "      <td>-1.497373</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>6</td>\n",
       "      <td>-9.507586</td>\n",
       "      <td>-2.117622</td>\n",
       "      <td>-33.048459</td>\n",
       "      <td>-1.202714</td>\n",
       "      <td>-47.380555</td>\n",
       "      <td>-1.171783</td>\n",
       "      <td>1.948457e-02</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>15.609408</td>\n",
       "      <td>0.438764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.052071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.388750</td>\n",
       "      <td>-1.449941</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.373598</td>\n",
       "      <td>-1.712748</td>\n",
       "      <td>-31.715595</td>\n",
       "      <td>-1.479207</td>\n",
       "      <td>-49.188299</td>\n",
       "      <td>-1.157867</td>\n",
       "      <td>7.363785e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.865982</td>\n",
       "      <td>0.227473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.046864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.547899</td>\n",
       "      <td>-1.427307</td>\n",
       "      <td>(rf, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>8</td>\n",
       "      <td>-12.159487</td>\n",
       "      <td>-1.952922</td>\n",
       "      <td>-30.787968</td>\n",
       "      <td>-1.294526</td>\n",
       "      <td>-48.804268</td>\n",
       "      <td>-1.034474</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.953677</td>\n",
       "      <td>0.386531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.031238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-31.095703</td>\n",
       "      <td>-1.871603</td>\n",
       "      <td>(rf, {'n_estimators': 10})</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>9</td>\n",
       "      <td>-8.723346</td>\n",
       "      <td>-2.015631</td>\n",
       "      <td>-37.736112</td>\n",
       "      <td>-2.042304</td>\n",
       "      <td>-46.921293</td>\n",
       "      <td>-1.556874</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.280388</td>\n",
       "      <td>0.222813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-31.473498</td>\n",
       "      <td>-1.765727</td>\n",
       "      <td>(rf, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>10</td>\n",
       "      <td>-11.423721</td>\n",
       "      <td>-2.706131</td>\n",
       "      <td>-35.263171</td>\n",
       "      <td>-1.281989</td>\n",
       "      <td>-47.830387</td>\n",
       "      <td>-1.309062</td>\n",
       "      <td>3.781439e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.096008</td>\n",
       "      <td>0.665058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.079405</td>\n",
       "      <td>-7.288251</td>\n",
       "      <td>(ada, {'n_estimators': 20})</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>11</td>\n",
       "      <td>-7.730682</td>\n",
       "      <td>-9.178531</td>\n",
       "      <td>-40.368896</td>\n",
       "      <td>-7.128777</td>\n",
       "      <td>-48.234227</td>\n",
       "      <td>-5.557444</td>\n",
       "      <td>3.371748e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.538816</td>\n",
       "      <td>1.482597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.099054</td>\n",
       "      <td>-2.196119</td>\n",
       "      <td>(rf, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>12</td>\n",
       "      <td>-11.525746</td>\n",
       "      <td>-3.664672</td>\n",
       "      <td>-35.011251</td>\n",
       "      <td>-1.506241</td>\n",
       "      <td>-49.865290</td>\n",
       "      <td>-1.417443</td>\n",
       "      <td>7.365864e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.779593</td>\n",
       "      <td>1.039057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.443368</td>\n",
       "      <td>-1.877476</td>\n",
       "      <td>(rf, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('rf', {'n_estim...</td>\n",
       "      <td>13</td>\n",
       "      <td>-13.613751</td>\n",
       "      <td>-2.685062</td>\n",
       "      <td>-33.299727</td>\n",
       "      <td>-1.490960</td>\n",
       "      <td>-50.523609</td>\n",
       "      <td>-1.456406</td>\n",
       "      <td>7.361874e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.073078</td>\n",
       "      <td>0.571224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>-32.878075</td>\n",
       "      <td>-7.550380</td>\n",
       "      <td>(ada, {'n_estimators': 20})</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>14</td>\n",
       "      <td>-9.833195</td>\n",
       "      <td>-9.982891</td>\n",
       "      <td>-37.010453</td>\n",
       "      <td>-6.862074</td>\n",
       "      <td>-51.903150</td>\n",
       "      <td>-5.806176</td>\n",
       "      <td>1.167225e-02</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>17.414067</td>\n",
       "      <td>1.773238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.015620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-33.538150</td>\n",
       "      <td>-7.987315</td>\n",
       "      <td>(ada, {'n_estimators': 10})</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>15</td>\n",
       "      <td>-10.069894</td>\n",
       "      <td>-10.792346</td>\n",
       "      <td>-39.568518</td>\n",
       "      <td>-7.420936</td>\n",
       "      <td>-51.079835</td>\n",
       "      <td>-5.748664</td>\n",
       "      <td>6.743496e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.270197</td>\n",
       "      <td>2.097661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.020829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.517659</td>\n",
       "      <td>-7.632310</td>\n",
       "      <td>(ada, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>16</td>\n",
       "      <td>-10.348420</td>\n",
       "      <td>-9.308273</td>\n",
       "      <td>-43.906131</td>\n",
       "      <td>-7.986928</td>\n",
       "      <td>-49.386406</td>\n",
       "      <td>-5.601728</td>\n",
       "      <td>7.363616e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.261035</td>\n",
       "      <td>1.533826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.026036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-35.035334</td>\n",
       "      <td>-7.342599</td>\n",
       "      <td>(ada, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>17</td>\n",
       "      <td>-9.453316</td>\n",
       "      <td>-9.543379</td>\n",
       "      <td>-36.656511</td>\n",
       "      <td>-7.053082</td>\n",
       "      <td>-59.138799</td>\n",
       "      <td>-5.431334</td>\n",
       "      <td>7.363673e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.306379</td>\n",
       "      <td>1.691172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-35.201739</td>\n",
       "      <td>-7.169883</td>\n",
       "      <td>(ada, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>18</td>\n",
       "      <td>-9.246306</td>\n",
       "      <td>-9.056361</td>\n",
       "      <td>-40.359880</td>\n",
       "      <td>-6.684255</td>\n",
       "      <td>-56.122823</td>\n",
       "      <td>-5.769031</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.473372</td>\n",
       "      <td>1.385282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>-35.583018</td>\n",
       "      <td>-7.015193</td>\n",
       "      <td>(gb, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>19</td>\n",
       "      <td>-10.138017</td>\n",
       "      <td>-8.887519</td>\n",
       "      <td>-40.920494</td>\n",
       "      <td>-6.495934</td>\n",
       "      <td>-55.810230</td>\n",
       "      <td>-5.662127</td>\n",
       "      <td>2.943431e-03</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>19.015744</td>\n",
       "      <td>1.366995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>-35.630914</td>\n",
       "      <td>-7.632627</td>\n",
       "      <td>(ada, {'n_estimators': 10})</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>20</td>\n",
       "      <td>-10.651511</td>\n",
       "      <td>-10.204136</td>\n",
       "      <td>-39.729155</td>\n",
       "      <td>-7.043843</td>\n",
       "      <td>-56.636369</td>\n",
       "      <td>-5.649901</td>\n",
       "      <td>6.743496e-07</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>18.986992</td>\n",
       "      <td>1.905302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.007224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-35.788261</td>\n",
       "      <td>-7.015193</td>\n",
       "      <td>(gb, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>21</td>\n",
       "      <td>-10.627302</td>\n",
       "      <td>-8.887519</td>\n",
       "      <td>-41.045726</td>\n",
       "      <td>-6.495934</td>\n",
       "      <td>-55.810230</td>\n",
       "      <td>-5.662127</td>\n",
       "      <td>6.431227e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.808821</td>\n",
       "      <td>1.366995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.012176</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>-35.827651</td>\n",
       "      <td>-7.015193</td>\n",
       "      <td>(gb, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>22</td>\n",
       "      <td>-10.107982</td>\n",
       "      <td>-8.887519</td>\n",
       "      <td>-41.682980</td>\n",
       "      <td>-6.495934</td>\n",
       "      <td>-55.810230</td>\n",
       "      <td>-5.662127</td>\n",
       "      <td>4.809433e-03</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>19.103983</td>\n",
       "      <td>1.366995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.010414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-35.865128</td>\n",
       "      <td>-7.015193</td>\n",
       "      <td>(gb, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>23</td>\n",
       "      <td>-10.251321</td>\n",
       "      <td>-8.887519</td>\n",
       "      <td>-41.675192</td>\n",
       "      <td>-6.495934</td>\n",
       "      <td>-55.786749</td>\n",
       "      <td>-5.662127</td>\n",
       "      <td>7.363897e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.030586</td>\n",
       "      <td>1.366995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>-35.960283</td>\n",
       "      <td>-7.015193</td>\n",
       "      <td>(gb, {'n_estimators': 20})</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>24</td>\n",
       "      <td>-10.253643</td>\n",
       "      <td>-8.887519</td>\n",
       "      <td>-41.934432</td>\n",
       "      <td>-6.495934</td>\n",
       "      <td>-55.810230</td>\n",
       "      <td>-5.662127</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>19.064464</td>\n",
       "      <td>1.366995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-36.021546</td>\n",
       "      <td>-8.105793</td>\n",
       "      <td>(ada, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>25</td>\n",
       "      <td>-8.006159</td>\n",
       "      <td>-10.985618</td>\n",
       "      <td>-39.996737</td>\n",
       "      <td>-7.033658</td>\n",
       "      <td>-60.204840</td>\n",
       "      <td>-6.298102</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.484618</td>\n",
       "      <td>2.058366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>-36.087357</td>\n",
       "      <td>-7.015193</td>\n",
       "      <td>(gb, {'n_estimators': 20})</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>26</td>\n",
       "      <td>-10.297294</td>\n",
       "      <td>-8.887519</td>\n",
       "      <td>-42.271251</td>\n",
       "      <td>-6.495934</td>\n",
       "      <td>-55.810230</td>\n",
       "      <td>-5.662127</td>\n",
       "      <td>3.236921e-03</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>19.080637</td>\n",
       "      <td>1.366995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>-36.861078</td>\n",
       "      <td>-7.269326</td>\n",
       "      <td>(ada, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>27</td>\n",
       "      <td>-9.149840</td>\n",
       "      <td>-8.754093</td>\n",
       "      <td>-44.750011</td>\n",
       "      <td>-6.669700</td>\n",
       "      <td>-56.801372</td>\n",
       "      <td>-6.384185</td>\n",
       "      <td>5.619580e-07</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>20.230606</td>\n",
       "      <td>1.056340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.036449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-37.513194</td>\n",
       "      <td>-7.166240</td>\n",
       "      <td>(ada, {'n_estimators': 20})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>28</td>\n",
       "      <td>-10.217914</td>\n",
       "      <td>-9.788698</td>\n",
       "      <td>-40.455449</td>\n",
       "      <td>-6.717145</td>\n",
       "      <td>-62.011177</td>\n",
       "      <td>-4.992876</td>\n",
       "      <td>7.364403e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.236429</td>\n",
       "      <td>1.983472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-37.531745</td>\n",
       "      <td>-8.031384</td>\n",
       "      <td>(ada, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>29</td>\n",
       "      <td>-8.763134</td>\n",
       "      <td>-10.768796</td>\n",
       "      <td>-48.681020</td>\n",
       "      <td>-7.153327</td>\n",
       "      <td>-55.255957</td>\n",
       "      <td>-6.172028</td>\n",
       "      <td>7.867412e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.548533</td>\n",
       "      <td>1.976665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-37.658510</td>\n",
       "      <td>-7.507154</td>\n",
       "      <td>(ada, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('ada', {'n_esti...</td>\n",
       "      <td>30</td>\n",
       "      <td>-7.904549</td>\n",
       "      <td>-9.769902</td>\n",
       "      <td>-47.061230</td>\n",
       "      <td>-7.118937</td>\n",
       "      <td>-58.130888</td>\n",
       "      <td>-5.632623</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.549132</td>\n",
       "      <td>1.711199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-50.297953</td>\n",
       "      <td>-17.535065</td>\n",
       "      <td>(gb, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>31</td>\n",
       "      <td>-16.290074</td>\n",
       "      <td>-22.879974</td>\n",
       "      <td>-66.544676</td>\n",
       "      <td>-15.066022</td>\n",
       "      <td>-68.164828</td>\n",
       "      <td>-14.659198</td>\n",
       "      <td>7.364010e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.091925</td>\n",
       "      <td>3.783069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>-50.548752</td>\n",
       "      <td>-17.535065</td>\n",
       "      <td>(gb, {'n_estimators': 10})</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>32</td>\n",
       "      <td>-16.463748</td>\n",
       "      <td>-22.879974</td>\n",
       "      <td>-67.121918</td>\n",
       "      <td>-15.066022</td>\n",
       "      <td>-68.164828</td>\n",
       "      <td>-14.659198</td>\n",
       "      <td>9.714006e-04</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>24.141222</td>\n",
       "      <td>3.783069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.008187</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>-50.601169</td>\n",
       "      <td>-17.535065</td>\n",
       "      <td>(gb, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>33</td>\n",
       "      <td>-16.463748</td>\n",
       "      <td>-22.879974</td>\n",
       "      <td>-67.278859</td>\n",
       "      <td>-15.066022</td>\n",
       "      <td>-68.164828</td>\n",
       "      <td>-14.659198</td>\n",
       "      <td>3.841836e-03</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>24.177293</td>\n",
       "      <td>3.783069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>-50.811002</td>\n",
       "      <td>-17.535065</td>\n",
       "      <td>(gb, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>34</td>\n",
       "      <td>-16.290074</td>\n",
       "      <td>-22.879974</td>\n",
       "      <td>-68.080789</td>\n",
       "      <td>-15.066022</td>\n",
       "      <td>-68.164828</td>\n",
       "      <td>-14.659198</td>\n",
       "      <td>9.400995e-04</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>24.446196</td>\n",
       "      <td>3.783069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>-51.192272</td>\n",
       "      <td>-17.535065</td>\n",
       "      <td>(gb, {'n_estimators': 10})</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>35</td>\n",
       "      <td>-16.642150</td>\n",
       "      <td>-22.879974</td>\n",
       "      <td>-68.870267</td>\n",
       "      <td>-15.066022</td>\n",
       "      <td>-68.164828</td>\n",
       "      <td>-14.659198</td>\n",
       "      <td>4.703592e-04</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>24.468539</td>\n",
       "      <td>3.783069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.010414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-51.227336</td>\n",
       "      <td>-17.535065</td>\n",
       "      <td>(gb, {'n_estimators': 10})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'regressor__selected_model': ('gb', {'n_estim...</td>\n",
       "      <td>36</td>\n",
       "      <td>-16.815823</td>\n",
       "      <td>-22.879974</td>\n",
       "      <td>-68.823242</td>\n",
       "      <td>-15.066022</td>\n",
       "      <td>-68.143037</td>\n",
       "      <td>-14.659198</td>\n",
       "      <td>7.363897e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.370270</td>\n",
       "      <td>3.783069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "1        0.026035         0.000000       -27.417126         -2.121529   \n",
       "5        0.026035         0.000000       -28.873305         -1.781403   \n",
       "11       0.046865         0.000000       -28.903251         -1.469765   \n",
       "6        0.057278         0.000000       -29.773320         -1.574397   \n",
       "9        0.046864         0.005207       -29.839364         -1.538114   \n",
       "10       0.052072         0.005207       -29.944476         -1.497373   \n",
       "8        0.052071         0.000000       -30.388750         -1.449941   \n",
       "7        0.046864         0.000000       -30.547899         -1.427307   \n",
       "4        0.031238         0.000000       -31.095703         -1.871603   \n",
       "2        0.015622         0.000000       -31.473498         -1.765727   \n",
       "22       0.031242         0.000000       -32.079405         -7.288251   \n",
       "0        0.026034         0.000000       -32.099054         -2.196119   \n",
       "3        0.026035         0.000000       -32.443368         -1.877476   \n",
       "23       0.030345         0.003865       -32.878075         -7.550380   \n",
       "16       0.015620         0.000000       -33.538150         -7.987315   \n",
       "14       0.020829         0.000000       -34.517659         -7.632310   \n",
       "21       0.026036         0.000000       -35.035334         -7.342599   \n",
       "19       0.031242         0.000000       -35.201739         -7.169883   \n",
       "30       0.004011         0.000333       -35.583018         -7.015193   \n",
       "17       0.015621         0.005207       -35.630914         -7.632627   \n",
       "33       0.007224         0.000000       -35.788261         -7.015193   \n",
       "32       0.012176         0.000665       -35.827651         -7.015193   \n",
       "31       0.010414         0.000000       -35.865128         -7.015193   \n",
       "34       0.000000         0.005207       -35.960283         -7.015193   \n",
       "12       0.015622         0.000000       -36.021546         -8.105793   \n",
       "35       0.011191         0.000750       -36.087357         -7.015193   \n",
       "20       0.031243         0.005207       -36.861078         -7.269326   \n",
       "18       0.036449         0.000000       -37.513194         -7.166240   \n",
       "15       0.015622         0.000000       -37.531745         -8.031384   \n",
       "13       0.015621         0.000000       -37.658510         -7.507154   \n",
       "24       0.005207         0.000000       -50.297953        -17.535065   \n",
       "28       0.000687         0.003200       -50.548752        -17.535065   \n",
       "26       0.008187         0.000667       -50.601169        -17.535065   \n",
       "27       0.004322         0.000333       -50.811002        -17.535065   \n",
       "29       0.005319         0.000665       -51.192272        -17.535065   \n",
       "25       0.010414         0.000000       -51.227336        -17.535065   \n",
       "\n",
       "   param_regressor__selected_model  \\\n",
       "1       (rf, {'n_estimators': 10})   \n",
       "5       (rf, {'n_estimators': 10})   \n",
       "11      (rf, {'n_estimators': 20})   \n",
       "6       (rf, {'n_estimators': 20})   \n",
       "9       (rf, {'n_estimators': 20})   \n",
       "10      (rf, {'n_estimators': 20})   \n",
       "8       (rf, {'n_estimators': 20})   \n",
       "7       (rf, {'n_estimators': 20})   \n",
       "4       (rf, {'n_estimators': 10})   \n",
       "2       (rf, {'n_estimators': 10})   \n",
       "22     (ada, {'n_estimators': 20})   \n",
       "0       (rf, {'n_estimators': 10})   \n",
       "3       (rf, {'n_estimators': 10})   \n",
       "23     (ada, {'n_estimators': 20})   \n",
       "16     (ada, {'n_estimators': 10})   \n",
       "14     (ada, {'n_estimators': 10})   \n",
       "21     (ada, {'n_estimators': 20})   \n",
       "19     (ada, {'n_estimators': 20})   \n",
       "30      (gb, {'n_estimators': 20})   \n",
       "17     (ada, {'n_estimators': 10})   \n",
       "33      (gb, {'n_estimators': 20})   \n",
       "32      (gb, {'n_estimators': 20})   \n",
       "31      (gb, {'n_estimators': 20})   \n",
       "34      (gb, {'n_estimators': 20})   \n",
       "12     (ada, {'n_estimators': 10})   \n",
       "35      (gb, {'n_estimators': 20})   \n",
       "20     (ada, {'n_estimators': 20})   \n",
       "18     (ada, {'n_estimators': 20})   \n",
       "15     (ada, {'n_estimators': 10})   \n",
       "13     (ada, {'n_estimators': 10})   \n",
       "24      (gb, {'n_estimators': 10})   \n",
       "28      (gb, {'n_estimators': 10})   \n",
       "26      (gb, {'n_estimators': 10})   \n",
       "27      (gb, {'n_estimators': 10})   \n",
       "29      (gb, {'n_estimators': 10})   \n",
       "25      (gb, {'n_estimators': 10})   \n",
       "\n",
       "                      param_scaler__selected_model  \\\n",
       "1    (std, {'with_mean': True, 'with_std': False})   \n",
       "5                                 (None, {}, True)   \n",
       "11                                (None, {}, True)   \n",
       "6     (std, {'with_mean': True, 'with_std': True})   \n",
       "9   (std, {'with_mean': False, 'with_std': False})   \n",
       "10                                       (max, {})   \n",
       "8    (std, {'with_mean': False, 'with_std': True})   \n",
       "7    (std, {'with_mean': True, 'with_std': False})   \n",
       "4                                        (max, {})   \n",
       "2    (std, {'with_mean': False, 'with_std': True})   \n",
       "22                                       (max, {})   \n",
       "0     (std, {'with_mean': True, 'with_std': True})   \n",
       "3   (std, {'with_mean': False, 'with_std': False})   \n",
       "23                                (None, {}, True)   \n",
       "16                                       (max, {})   \n",
       "14   (std, {'with_mean': False, 'with_std': True})   \n",
       "21  (std, {'with_mean': False, 'with_std': False})   \n",
       "19   (std, {'with_mean': True, 'with_std': False})   \n",
       "30    (std, {'with_mean': True, 'with_std': True})   \n",
       "17                                (None, {}, True)   \n",
       "33  (std, {'with_mean': False, 'with_std': False})   \n",
       "32   (std, {'with_mean': False, 'with_std': True})   \n",
       "31   (std, {'with_mean': True, 'with_std': False})   \n",
       "34                                       (max, {})   \n",
       "12    (std, {'with_mean': True, 'with_std': True})   \n",
       "35                                (None, {}, True)   \n",
       "20   (std, {'with_mean': False, 'with_std': True})   \n",
       "18    (std, {'with_mean': True, 'with_std': True})   \n",
       "15  (std, {'with_mean': False, 'with_std': False})   \n",
       "13   (std, {'with_mean': True, 'with_std': False})   \n",
       "24    (std, {'with_mean': True, 'with_std': True})   \n",
       "28                                       (max, {})   \n",
       "26   (std, {'with_mean': False, 'with_std': True})   \n",
       "27  (std, {'with_mean': False, 'with_std': False})   \n",
       "29                                (None, {}, True)   \n",
       "25   (std, {'with_mean': True, 'with_std': False})   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "1   {'regressor__selected_model': ('rf', {'n_estim...                1   \n",
       "5   {'regressor__selected_model': ('rf', {'n_estim...                2   \n",
       "11  {'regressor__selected_model': ('rf', {'n_estim...                3   \n",
       "6   {'regressor__selected_model': ('rf', {'n_estim...                4   \n",
       "9   {'regressor__selected_model': ('rf', {'n_estim...                5   \n",
       "10  {'regressor__selected_model': ('rf', {'n_estim...                6   \n",
       "8   {'regressor__selected_model': ('rf', {'n_estim...                7   \n",
       "7   {'regressor__selected_model': ('rf', {'n_estim...                8   \n",
       "4   {'regressor__selected_model': ('rf', {'n_estim...                9   \n",
       "2   {'regressor__selected_model': ('rf', {'n_estim...               10   \n",
       "22  {'regressor__selected_model': ('ada', {'n_esti...               11   \n",
       "0   {'regressor__selected_model': ('rf', {'n_estim...               12   \n",
       "3   {'regressor__selected_model': ('rf', {'n_estim...               13   \n",
       "23  {'regressor__selected_model': ('ada', {'n_esti...               14   \n",
       "16  {'regressor__selected_model': ('ada', {'n_esti...               15   \n",
       "14  {'regressor__selected_model': ('ada', {'n_esti...               16   \n",
       "21  {'regressor__selected_model': ('ada', {'n_esti...               17   \n",
       "19  {'regressor__selected_model': ('ada', {'n_esti...               18   \n",
       "30  {'regressor__selected_model': ('gb', {'n_estim...               19   \n",
       "17  {'regressor__selected_model': ('ada', {'n_esti...               20   \n",
       "33  {'regressor__selected_model': ('gb', {'n_estim...               21   \n",
       "32  {'regressor__selected_model': ('gb', {'n_estim...               22   \n",
       "31  {'regressor__selected_model': ('gb', {'n_estim...               23   \n",
       "34  {'regressor__selected_model': ('gb', {'n_estim...               24   \n",
       "12  {'regressor__selected_model': ('ada', {'n_esti...               25   \n",
       "35  {'regressor__selected_model': ('gb', {'n_estim...               26   \n",
       "20  {'regressor__selected_model': ('ada', {'n_esti...               27   \n",
       "18  {'regressor__selected_model': ('ada', {'n_esti...               28   \n",
       "15  {'regressor__selected_model': ('ada', {'n_esti...               29   \n",
       "13  {'regressor__selected_model': ('ada', {'n_esti...               30   \n",
       "24  {'regressor__selected_model': ('gb', {'n_estim...               31   \n",
       "28  {'regressor__selected_model': ('gb', {'n_estim...               32   \n",
       "26  {'regressor__selected_model': ('gb', {'n_estim...               33   \n",
       "27  {'regressor__selected_model': ('gb', {'n_estim...               34   \n",
       "29  {'regressor__selected_model': ('gb', {'n_estim...               35   \n",
       "25  {'regressor__selected_model': ('gb', {'n_estim...               36   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "1          -10.189778           -2.794439         -27.574961   \n",
       "5           -8.302500           -2.424125         -30.776126   \n",
       "11          -9.290991           -1.707056         -32.118273   \n",
       "6          -12.202377           -2.009331         -30.714959   \n",
       "9          -10.834350           -1.927962         -30.986804   \n",
       "10          -9.507586           -2.117622         -33.048459   \n",
       "8          -10.373598           -1.712748         -31.715595   \n",
       "7          -12.159487           -1.952922         -30.787968   \n",
       "4           -8.723346           -2.015631         -37.736112   \n",
       "2          -11.423721           -2.706131         -35.263171   \n",
       "22          -7.730682           -9.178531         -40.368896   \n",
       "0          -11.525746           -3.664672         -35.011251   \n",
       "3          -13.613751           -2.685062         -33.299727   \n",
       "23          -9.833195           -9.982891         -37.010453   \n",
       "16         -10.069894          -10.792346         -39.568518   \n",
       "14         -10.348420           -9.308273         -43.906131   \n",
       "21          -9.453316           -9.543379         -36.656511   \n",
       "19          -9.246306           -9.056361         -40.359880   \n",
       "30         -10.138017           -8.887519         -40.920494   \n",
       "17         -10.651511          -10.204136         -39.729155   \n",
       "33         -10.627302           -8.887519         -41.045726   \n",
       "32         -10.107982           -8.887519         -41.682980   \n",
       "31         -10.251321           -8.887519         -41.675192   \n",
       "34         -10.253643           -8.887519         -41.934432   \n",
       "12          -8.006159          -10.985618         -39.996737   \n",
       "35         -10.297294           -8.887519         -42.271251   \n",
       "20          -9.149840           -8.754093         -44.750011   \n",
       "18         -10.217914           -9.788698         -40.455449   \n",
       "15          -8.763134          -10.768796         -48.681020   \n",
       "13          -7.904549           -9.769902         -47.061230   \n",
       "24         -16.290074          -22.879974         -66.544676   \n",
       "28         -16.463748          -22.879974         -67.121918   \n",
       "26         -16.463748          -22.879974         -67.278859   \n",
       "27         -16.290074          -22.879974         -68.080789   \n",
       "29         -16.642150          -22.879974         -68.870267   \n",
       "25         -16.815823          -22.879974         -68.823242   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "1            -2.174025         -44.588243           -1.396122  7.366596e-03   \n",
       "5            -1.572546         -47.652407           -1.347537  7.363785e-03   \n",
       "11           -1.590325         -45.398091           -1.111915  0.000000e+00   \n",
       "6            -1.480838         -46.501607           -1.233023  1.472813e-02   \n",
       "9            -1.502737         -47.803233           -1.183645  0.000000e+00   \n",
       "10           -1.202714         -47.380555           -1.171783  1.948457e-02   \n",
       "8            -1.479207         -49.188299           -1.157867  7.363785e-03   \n",
       "7            -1.294526         -48.804268           -1.034474  0.000000e+00   \n",
       "4            -2.042304         -46.921293           -1.556874  0.000000e+00   \n",
       "2            -1.281989         -47.830387           -1.309062  3.781439e-06   \n",
       "22           -7.128777         -48.234227           -5.557444  3.371748e-07   \n",
       "0            -1.506241         -49.865290           -1.417443  7.365864e-03   \n",
       "3            -1.490960         -50.523609           -1.456406  7.361874e-03   \n",
       "23           -6.862074         -51.903150           -5.806176  1.167225e-02   \n",
       "16           -7.420936         -51.079835           -5.748664  6.743496e-07   \n",
       "14           -7.986928         -49.386406           -5.601728  7.363616e-03   \n",
       "21           -7.053082         -59.138799           -5.431334  7.363673e-03   \n",
       "19           -6.684255         -56.122823           -5.769031  2.973602e-07   \n",
       "30           -6.495934         -55.810230           -5.662127  2.943431e-03   \n",
       "17           -7.043843         -56.636369           -5.649901  6.743496e-07   \n",
       "33           -6.495934         -55.810230           -5.662127  6.431227e-03   \n",
       "32           -6.495934         -55.810230           -5.662127  4.809433e-03   \n",
       "31           -6.495934         -55.786749           -5.662127  7.363897e-03   \n",
       "34           -6.495934         -55.810230           -5.662127  0.000000e+00   \n",
       "12           -7.033658         -60.204840           -6.298102  0.000000e+00   \n",
       "35           -6.495934         -55.810230           -5.662127  3.236921e-03   \n",
       "20           -6.669700         -56.801372           -6.384185  5.619580e-07   \n",
       "18           -6.717145         -62.011177           -4.992876  7.364403e-03   \n",
       "15           -7.153327         -55.255957           -6.172028  7.867412e-07   \n",
       "13           -7.118937         -58.130888           -5.632623  0.000000e+00   \n",
       "24          -15.066022         -68.164828          -14.659198  7.364010e-03   \n",
       "28          -15.066022         -68.164828          -14.659198  9.714006e-04   \n",
       "26          -15.066022         -68.164828          -14.659198  3.841836e-03   \n",
       "27          -15.066022         -68.164828          -14.659198  9.400995e-04   \n",
       "29          -15.066022         -68.164828          -14.659198  4.703592e-04   \n",
       "25          -15.066022         -68.143037          -14.659198  7.363897e-03   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "1         0.000000       14.036558         0.572066  \n",
       "5         0.000000       16.112965         0.463664  \n",
       "11        0.000000       14.908186         0.257487  \n",
       "6         0.000000       14.011497         0.323757  \n",
       "9         0.007364       15.106827         0.304894  \n",
       "10        0.007363       15.609408         0.438764  \n",
       "8         0.000000       15.865982         0.227473  \n",
       "7         0.000000       14.953677         0.386531  \n",
       "4         0.000000       16.280388         0.222813  \n",
       "2         0.000000       15.096008         0.665058  \n",
       "22        0.000000       17.538816         1.482597  \n",
       "0         0.000000       15.779593         1.039057  \n",
       "3         0.000000       15.073078         0.571224  \n",
       "23        0.004137       17.414067         1.773238  \n",
       "16        0.000000       17.270197         2.097661  \n",
       "14        0.000000       17.261035         1.533826  \n",
       "21        0.000000       20.306379         1.691172  \n",
       "19        0.000000       19.473372         1.385282  \n",
       "30        0.000470       19.015744         1.366995  \n",
       "17        0.007364       18.986992         1.905302  \n",
       "33        0.000000       18.808821         1.366995  \n",
       "32        0.000470       19.103983         1.366995  \n",
       "31        0.000000       19.030586         1.366995  \n",
       "34        0.007364       19.064464         1.366995  \n",
       "12        0.000000       21.484618         2.058366  \n",
       "35        0.000351       19.080637         1.366995  \n",
       "20        0.007364       20.230606         1.056340  \n",
       "18        0.000000       21.236429         1.983472  \n",
       "15        0.000000       20.548533         1.976665  \n",
       "13        0.000000       21.549132         1.711199  \n",
       "24        0.000000       24.091925         3.783069  \n",
       "28        0.004526       24.141222         3.783069  \n",
       "26        0.000471       24.177293         3.783069  \n",
       "27        0.000470       24.446196         3.783069  \n",
       "29        0.000470       24.468539         3.783069  \n",
       "25        0.000000       24.370270         3.783069  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  Iris (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T15:41:17.217444Z",
     "start_time": "2019-02-14T15:40:19.783311Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2892 candidates, totalling 8676 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1482 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 3694 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4826 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=-1)]: Done 7220 tasks      | elapsed:   53.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__selected_model': ('knn', {'n_neighbors': 5, 'leaf_size': 1, 'weights': 'uniform', 'algorithm': 'auto'}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': False})}\n",
      "0.9866666666666667\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 8676 out of 8676 | elapsed:   57.2s finished\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from pipelinehelper import PipelineHelper\n",
    "\n",
    "X, y = datasets.load_iris(True)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', PipelineHelper([\n",
    "        ('std', StandardScaler()),\n",
    "        ('max', MaxAbsScaler()),\n",
    "    ], include_bypass=True)), # this will produce one setting without scaler\n",
    "    ('classifier', PipelineHelper([\n",
    "        ('svm', SVC()),\n",
    "        ('rf', RandomForestClassifier()),\n",
    "        ('ada', AdaBoostClassifier()),\n",
    "        ('gb', GradientBoostingClassifier()),\n",
    "        ('knn', KNeighborsClassifier()),\n",
    "        \n",
    "        ('nb_pipe', Pipeline([\n",
    "            # Naivie Bayes needs positive numbers\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('nb', MultinomialNB())\n",
    "        ])),\n",
    "    ])),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'scaler__selected_model': pipe.named_steps['scaler'].generate({\n",
    "        'std__with_mean': [True, False],\n",
    "        'std__with_std': [True, False],\n",
    "        # no params for 'max' leads to using standard params\n",
    "    }),\n",
    "    'classifier__selected_model': pipe.named_steps['classifier'].generate({\n",
    "\n",
    "        'svm__C': [0.1, 1.0],\n",
    "        'svm__kernel': ['linear', 'rbf'],\n",
    "\n",
    "        'rf__n_estimators': [10, 20, 50, 100, 150],\n",
    "        'rf__max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'rf__min_samples_split' : [2, 5, 10],\n",
    "        'rf__min_samples_leaf' : [1, 2, 4],\n",
    "        'rf__bootstrap': [True, False],\n",
    "\n",
    "        'ada__n_estimators': [10, 20, 40, 100],\n",
    "        'ada__algorithm': ['SAMME', 'SAMME.R'],\n",
    "        \n",
    "        'gb__n_estimators': [10, 20, 50, 100],\n",
    "        'gb__criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "        'gb__max_features': ['auto', 'sqrt', None],\n",
    "\n",
    "        'knn__n_neighbors': [2, 3, 5, 7, 10],\n",
    "        'knn__leaf_size':[1,2,3,5],\n",
    "        'knn__weights': ['uniform', 'distance'],\n",
    "        'knn__algorithm': ['auto', 'ball_tree','kd_tree','brute'],\n",
    "\n",
    "        'nb_pipe__nb__fit_prior': [True, False],\n",
    "        'nb_pipe__nb__alpha': [0.1, 0.2],\n",
    "    })\n",
    "}\n",
    "grid = GridSearchCV(pipe, params, scoring='accuracy', verbose=2, n_jobs=-1, return_train_score=True)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T15:35:39.582537Z",
     "start_time": "2019-02-14T15:35:39.472615Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_classifier__selected_model</th>\n",
       "      <th>param_scaler__selected_model</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>(knn, {'n_neighbors': 5, 'leaf_size': 1, 'weig...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.009256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.364122e-03</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>(knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.363897e-03</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.009256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>(knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.363897e-03</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.009256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>(knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.009256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>(knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.009256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>(knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.009256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>(knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.009256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>(knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.009256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>(knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.009256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>(knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.009256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.364010e-03</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.364010e-03</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(knn, {'n_neighbors': 10, 'leaf_size': 2, 'wei...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.980095</td>\n",
       "      <td>(knn, {'n_neighbors': 2, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>2835</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>1.880592e-03</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.024421</td>\n",
       "      <td>0.007886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.980095</td>\n",
       "      <td>(knn, {'n_neighbors': 2, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>2835</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>8.142961e-04</td>\n",
       "      <td>4.703589e-04</td>\n",
       "      <td>0.024421</td>\n",
       "      <td>0.007886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.980095</td>\n",
       "      <td>(knn, {'n_neighbors': 2, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>2835</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>5.150430e-07</td>\n",
       "      <td>2.247832e-07</td>\n",
       "      <td>0.024421</td>\n",
       "      <td>0.007886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.980095</td>\n",
       "      <td>(knn, {'n_neighbors': 2, 'leaf_size': 2, 'weig...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('knn', {'n_nei...</td>\n",
       "      <td>2835</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>0.024421</td>\n",
       "      <td>0.007886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.906417</td>\n",
       "      <td>(svm, {'C': 0.1, 'kernel': 'rbf'})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('svm', {'C': 0...</td>\n",
       "      <td>2867</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.030870</td>\n",
       "      <td>0.018122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.906417</td>\n",
       "      <td>(svm, {'C': 0.1, 'kernel': 'rbf'})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('svm', {'C': 0...</td>\n",
       "      <td>2867</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.030870</td>\n",
       "      <td>0.018122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2869</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>7.363785e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(max, {})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': False})</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>0.010414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>(nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...</td>\n",
       "      <td>(None, {}, True)</td>\n",
       "      <td>{'classifier__selected_model': ('nb_pipe', {'n...</td>\n",
       "      <td>2881</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>7.363785e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.013912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2892 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "2305       0.000000         0.000000         0.986667          0.966726   \n",
       "2713       0.000000         0.000000         0.986667          1.000000   \n",
       "2709       0.000000         0.000000         0.986667          1.000000   \n",
       "2707       0.000000         0.000000         0.986667          1.000000   \n",
       "2705       0.000000         0.005207         0.986667          1.000000   \n",
       "2341       0.000000         0.005207         0.986667          0.966726   \n",
       "2343       0.000000         0.005207         0.986667          0.966726   \n",
       "2345       0.000000         0.000000         0.986667          0.966726   \n",
       "2797       0.000000         0.000000         0.986667          1.000000   \n",
       "2347       0.000000         0.000000         0.986667          0.966726   \n",
       "2349       0.000000         0.000000         0.986667          0.966726   \n",
       "2351       0.000000         0.000000         0.986667          0.966726   \n",
       "2799       0.000000         0.000000         0.986667          1.000000   \n",
       "2801       0.000000         0.000000         0.986667          1.000000   \n",
       "2353       0.000000         0.000000         0.986667          0.966726   \n",
       "2355       0.000000         0.000000         0.986667          0.966726   \n",
       "2803       0.000000         0.000000         0.986667          1.000000   \n",
       "2357       0.000000         0.000000         0.986667          0.966726   \n",
       "2703       0.000000         0.000000         0.986667          1.000000   \n",
       "2807       0.000000         0.000000         0.986667          1.000000   \n",
       "2701       0.000000         0.000000         0.986667          1.000000   \n",
       "2809       0.000000         0.000000         0.986667          1.000000   \n",
       "2811       0.000000         0.005207         0.986667          1.000000   \n",
       "2813       0.000000         0.005207         0.986667          1.000000   \n",
       "2815       0.000000         0.000000         0.986667          1.000000   \n",
       "2711       0.000000         0.000000         0.986667          1.000000   \n",
       "2715       0.000000         0.000000         0.986667          1.000000   \n",
       "2819       0.000000         0.000000         0.986667          1.000000   \n",
       "2717       0.000000         0.000000         0.986667          1.000000   \n",
       "2749       0.000000         0.000000         0.986667          1.000000   \n",
       "...             ...              ...              ...               ...   \n",
       "1962       0.002327         0.000997         0.933333          0.980095   \n",
       "1964       0.000997         0.001330         0.933333          0.980095   \n",
       "1968       0.000997         0.000997         0.933333          0.980095   \n",
       "1970       0.000997         0.000997         0.933333          0.980095   \n",
       "8          0.000000         0.000000         0.920000          0.906417   \n",
       "6          0.000000         0.000000         0.920000          0.906417   \n",
       "2880       0.000000         0.000000         0.793333          0.800158   \n",
       "2885       0.000000         0.000000         0.793333          0.800158   \n",
       "2884       0.000000         0.000000         0.793333          0.800158   \n",
       "2883       0.000000         0.000000         0.793333          0.800158   \n",
       "2882       0.000000         0.000000         0.793333          0.800158   \n",
       "2881       0.000000         0.000000         0.793333          0.800158   \n",
       "2872       0.000000         0.000000         0.793333          0.800158   \n",
       "2870       0.000000         0.000000         0.793333          0.800158   \n",
       "2868       0.000000         0.000000         0.793333          0.800158   \n",
       "2873       0.000000         0.000000         0.793333          0.800158   \n",
       "2871       0.000000         0.000000         0.793333          0.800158   \n",
       "2869       0.000000         0.000000         0.793333          0.800158   \n",
       "2890       0.000000         0.000000         0.786667          0.800158   \n",
       "2889       0.000000         0.000000         0.786667          0.800158   \n",
       "2888       0.000000         0.000000         0.786667          0.800158   \n",
       "2887       0.005207         0.000000         0.786667          0.800158   \n",
       "2886       0.000000         0.000000         0.786667          0.800158   \n",
       "2875       0.000000         0.000000         0.786667          0.800158   \n",
       "2876       0.000000         0.000000         0.786667          0.800158   \n",
       "2874       0.000000         0.000000         0.786667          0.800158   \n",
       "2879       0.000000         0.000000         0.786667          0.800158   \n",
       "2878       0.000000         0.000000         0.786667          0.800158   \n",
       "2877       0.000000         0.000000         0.786667          0.800158   \n",
       "2891       0.010414         0.000000         0.786667          0.800158   \n",
       "\n",
       "                       param_classifier__selected_model  \\\n",
       "2305  (knn, {'n_neighbors': 5, 'leaf_size': 1, 'weig...   \n",
       "2713  (knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...   \n",
       "2709  (knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...   \n",
       "2707  (knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...   \n",
       "2705  (knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...   \n",
       "2341  (knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...   \n",
       "2343  (knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...   \n",
       "2345  (knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...   \n",
       "2797  (knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...   \n",
       "2347  (knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...   \n",
       "2349  (knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...   \n",
       "2351  (knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...   \n",
       "2799  (knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...   \n",
       "2801  (knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...   \n",
       "2353  (knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...   \n",
       "2355  (knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...   \n",
       "2803  (knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...   \n",
       "2357  (knn, {'n_neighbors': 5, 'leaf_size': 2, 'weig...   \n",
       "2703  (knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...   \n",
       "2807  (knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...   \n",
       "2701  (knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...   \n",
       "2809  (knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...   \n",
       "2811  (knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...   \n",
       "2813  (knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...   \n",
       "2815  (knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...   \n",
       "2711  (knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...   \n",
       "2715  (knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...   \n",
       "2819  (knn, {'n_neighbors': 10, 'leaf_size': 3, 'wei...   \n",
       "2717  (knn, {'n_neighbors': 10, 'leaf_size': 1, 'wei...   \n",
       "2749  (knn, {'n_neighbors': 10, 'leaf_size': 2, 'wei...   \n",
       "...                                                 ...   \n",
       "1962  (knn, {'n_neighbors': 2, 'leaf_size': 2, 'weig...   \n",
       "1964  (knn, {'n_neighbors': 2, 'leaf_size': 2, 'weig...   \n",
       "1968  (knn, {'n_neighbors': 2, 'leaf_size': 2, 'weig...   \n",
       "1970  (knn, {'n_neighbors': 2, 'leaf_size': 2, 'weig...   \n",
       "8                    (svm, {'C': 0.1, 'kernel': 'rbf'})   \n",
       "6                    (svm, {'C': 0.1, 'kernel': 'rbf'})   \n",
       "2880  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "2885  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "2884  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "2883  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "2882  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "2881  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "2872  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2870  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2868  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2873  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2871  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2869  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2890  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "2889  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "2888  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "2887  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "2886  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "2875  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2876  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2874  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2879  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2878  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2877  (nb_pipe, {'nb__fit_prior': True, 'nb__alpha':...   \n",
       "2891  (nb_pipe, {'nb__fit_prior': False, 'nb__alpha'...   \n",
       "\n",
       "                        param_scaler__selected_model  \\\n",
       "2305   (std, {'with_mean': True, 'with_std': False})   \n",
       "2713   (std, {'with_mean': True, 'with_std': False})   \n",
       "2709  (std, {'with_mean': False, 'with_std': False})   \n",
       "2707   (std, {'with_mean': True, 'with_std': False})   \n",
       "2705                                (None, {}, True)   \n",
       "2341   (std, {'with_mean': True, 'with_std': False})   \n",
       "2343  (std, {'with_mean': False, 'with_std': False})   \n",
       "2345                                (None, {}, True)   \n",
       "2797   (std, {'with_mean': True, 'with_std': False})   \n",
       "2347   (std, {'with_mean': True, 'with_std': False})   \n",
       "2349  (std, {'with_mean': False, 'with_std': False})   \n",
       "2351                                (None, {}, True)   \n",
       "2799  (std, {'with_mean': False, 'with_std': False})   \n",
       "2801                                (None, {}, True)   \n",
       "2353   (std, {'with_mean': True, 'with_std': False})   \n",
       "2355  (std, {'with_mean': False, 'with_std': False})   \n",
       "2803   (std, {'with_mean': True, 'with_std': False})   \n",
       "2357                                (None, {}, True)   \n",
       "2703  (std, {'with_mean': False, 'with_std': False})   \n",
       "2807                                (None, {}, True)   \n",
       "2701   (std, {'with_mean': True, 'with_std': False})   \n",
       "2809   (std, {'with_mean': True, 'with_std': False})   \n",
       "2811  (std, {'with_mean': False, 'with_std': False})   \n",
       "2813                                (None, {}, True)   \n",
       "2815   (std, {'with_mean': True, 'with_std': False})   \n",
       "2711                                (None, {}, True)   \n",
       "2715  (std, {'with_mean': False, 'with_std': False})   \n",
       "2819                                (None, {}, True)   \n",
       "2717                                (None, {}, True)   \n",
       "2749   (std, {'with_mean': True, 'with_std': False})   \n",
       "...                                              ...   \n",
       "1962    (std, {'with_mean': True, 'with_std': True})   \n",
       "1964   (std, {'with_mean': False, 'with_std': True})   \n",
       "1968    (std, {'with_mean': True, 'with_std': True})   \n",
       "1970   (std, {'with_mean': False, 'with_std': True})   \n",
       "8      (std, {'with_mean': False, 'with_std': True})   \n",
       "6       (std, {'with_mean': True, 'with_std': True})   \n",
       "2880    (std, {'with_mean': True, 'with_std': True})   \n",
       "2885                                (None, {}, True)   \n",
       "2884                                       (max, {})   \n",
       "2883  (std, {'with_mean': False, 'with_std': False})   \n",
       "2882   (std, {'with_mean': False, 'with_std': True})   \n",
       "2881   (std, {'with_mean': True, 'with_std': False})   \n",
       "2872                                       (max, {})   \n",
       "2870   (std, {'with_mean': False, 'with_std': True})   \n",
       "2868    (std, {'with_mean': True, 'with_std': True})   \n",
       "2873                                (None, {}, True)   \n",
       "2871  (std, {'with_mean': False, 'with_std': False})   \n",
       "2869   (std, {'with_mean': True, 'with_std': False})   \n",
       "2890                                       (max, {})   \n",
       "2889  (std, {'with_mean': False, 'with_std': False})   \n",
       "2888   (std, {'with_mean': False, 'with_std': True})   \n",
       "2887   (std, {'with_mean': True, 'with_std': False})   \n",
       "2886    (std, {'with_mean': True, 'with_std': True})   \n",
       "2875   (std, {'with_mean': True, 'with_std': False})   \n",
       "2876   (std, {'with_mean': False, 'with_std': True})   \n",
       "2874    (std, {'with_mean': True, 'with_std': True})   \n",
       "2879                                (None, {}, True)   \n",
       "2878                                       (max, {})   \n",
       "2877  (std, {'with_mean': False, 'with_std': False})   \n",
       "2891                                (None, {}, True)   \n",
       "\n",
       "                                                 params  rank_test_score  \\\n",
       "2305  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2713  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2709  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2707  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2705  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2341  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2343  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2345  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2797  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2347  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2349  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2351  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2799  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2801  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2353  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2355  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2803  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2357  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2703  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2807  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2701  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2809  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2811  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2813  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2815  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2711  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2715  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2819  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2717  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "2749  {'classifier__selected_model': ('knn', {'n_nei...                1   \n",
       "...                                                 ...              ...   \n",
       "1962  {'classifier__selected_model': ('knn', {'n_nei...             2835   \n",
       "1964  {'classifier__selected_model': ('knn', {'n_nei...             2835   \n",
       "1968  {'classifier__selected_model': ('knn', {'n_nei...             2835   \n",
       "1970  {'classifier__selected_model': ('knn', {'n_nei...             2835   \n",
       "8     {'classifier__selected_model': ('svm', {'C': 0...             2867   \n",
       "6     {'classifier__selected_model': ('svm', {'C': 0...             2867   \n",
       "2880  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2885  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2884  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2883  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2882  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2881  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2872  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2870  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2868  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2873  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2871  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2869  {'classifier__selected_model': ('nb_pipe', {'n...             2869   \n",
       "2890  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "2889  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "2888  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "2887  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "2886  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "2875  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "2876  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "2874  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "2879  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "2878  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "2877  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "2891  {'classifier__selected_model': ('nb_pipe', {'n...             2881   \n",
       "\n",
       "      split0_test_score  split0_train_score  split1_test_score  \\\n",
       "2305           0.980392            0.959596           0.980392   \n",
       "2713           0.980392            1.000000           0.980392   \n",
       "2709           0.980392            1.000000           0.980392   \n",
       "2707           0.980392            1.000000           0.980392   \n",
       "2705           0.980392            1.000000           0.980392   \n",
       "2341           0.980392            0.959596           0.980392   \n",
       "2343           0.980392            0.959596           0.980392   \n",
       "2345           0.980392            0.959596           0.980392   \n",
       "2797           0.980392            1.000000           0.980392   \n",
       "2347           0.980392            0.959596           0.980392   \n",
       "2349           0.980392            0.959596           0.980392   \n",
       "2351           0.980392            0.959596           0.980392   \n",
       "2799           0.980392            1.000000           0.980392   \n",
       "2801           0.980392            1.000000           0.980392   \n",
       "2353           0.980392            0.959596           0.980392   \n",
       "2355           0.980392            0.959596           0.980392   \n",
       "2803           0.980392            1.000000           0.980392   \n",
       "2357           0.980392            0.959596           0.980392   \n",
       "2703           0.980392            1.000000           0.980392   \n",
       "2807           0.980392            1.000000           0.980392   \n",
       "2701           0.980392            1.000000           0.980392   \n",
       "2809           0.980392            1.000000           0.980392   \n",
       "2811           0.980392            1.000000           0.980392   \n",
       "2813           0.980392            1.000000           0.980392   \n",
       "2815           0.980392            1.000000           0.980392   \n",
       "2711           0.980392            1.000000           0.980392   \n",
       "2715           0.980392            1.000000           0.980392   \n",
       "2819           0.980392            1.000000           0.980392   \n",
       "2717           0.980392            1.000000           0.980392   \n",
       "2749           0.980392            1.000000           0.980392   \n",
       "...                 ...                 ...                ...   \n",
       "1962           0.960784            0.979798           0.901961   \n",
       "1964           0.960784            0.979798           0.901961   \n",
       "1968           0.960784            0.979798           0.901961   \n",
       "1970           0.960784            0.979798           0.901961   \n",
       "8              0.882353            0.888889           0.921569   \n",
       "6              0.882353            0.888889           0.921569   \n",
       "2880           0.803922            0.797980           0.764706   \n",
       "2885           0.803922            0.797980           0.764706   \n",
       "2884           0.803922            0.797980           0.764706   \n",
       "2883           0.803922            0.797980           0.764706   \n",
       "2882           0.803922            0.797980           0.764706   \n",
       "2881           0.803922            0.797980           0.764706   \n",
       "2872           0.803922            0.797980           0.764706   \n",
       "2870           0.803922            0.797980           0.764706   \n",
       "2868           0.803922            0.797980           0.764706   \n",
       "2873           0.803922            0.797980           0.764706   \n",
       "2871           0.803922            0.797980           0.764706   \n",
       "2869           0.803922            0.797980           0.764706   \n",
       "2890           0.784314            0.797980           0.764706   \n",
       "2889           0.784314            0.797980           0.764706   \n",
       "2888           0.784314            0.797980           0.764706   \n",
       "2887           0.784314            0.797980           0.764706   \n",
       "2886           0.784314            0.797980           0.764706   \n",
       "2875           0.784314            0.797980           0.764706   \n",
       "2876           0.784314            0.797980           0.764706   \n",
       "2874           0.784314            0.797980           0.764706   \n",
       "2879           0.784314            0.797980           0.764706   \n",
       "2878           0.784314            0.797980           0.764706   \n",
       "2877           0.784314            0.797980           0.764706   \n",
       "2891           0.784314            0.797980           0.764706   \n",
       "\n",
       "      split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "2305            0.979798           1.000000            0.960784  0.000000e+00   \n",
       "2713            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2709            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2707            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2705            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2341            0.979798           1.000000            0.960784  0.000000e+00   \n",
       "2343            0.979798           1.000000            0.960784  0.000000e+00   \n",
       "2345            0.979798           1.000000            0.960784  0.000000e+00   \n",
       "2797            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2347            0.979798           1.000000            0.960784  0.000000e+00   \n",
       "2349            0.979798           1.000000            0.960784  0.000000e+00   \n",
       "2351            0.979798           1.000000            0.960784  0.000000e+00   \n",
       "2799            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2801            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2353            0.979798           1.000000            0.960784  0.000000e+00   \n",
       "2355            0.979798           1.000000            0.960784  0.000000e+00   \n",
       "2803            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2357            0.979798           1.000000            0.960784  0.000000e+00   \n",
       "2703            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2807            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2701            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2809            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2811            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2813            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2815            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2711            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2715            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2819            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2717            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "2749            1.000000           1.000000            1.000000  0.000000e+00   \n",
       "...                  ...                ...                 ...           ...   \n",
       "1962            0.989899           0.937500            0.970588  1.880592e-03   \n",
       "1964            0.989899           0.937500            0.970588  8.142961e-04   \n",
       "1968            0.989899           0.937500            0.970588  5.150430e-07   \n",
       "1970            0.989899           0.937500            0.970588  1.123916e-07   \n",
       "8               0.898990           0.958333            0.931373  0.000000e+00   \n",
       "6               0.898990           0.958333            0.931373  0.000000e+00   \n",
       "2880            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2885            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2884            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2883            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2882            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2881            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2872            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2870            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2868            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2873            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2871            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2869            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2890            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2889            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2888            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2887            0.818182           0.812500            0.784314  7.363785e-03   \n",
       "2886            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2875            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2876            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2874            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2879            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2878            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2877            0.818182           0.812500            0.784314  0.000000e+00   \n",
       "2891            0.818182           0.812500            0.784314  7.363785e-03   \n",
       "\n",
       "      std_score_time  std_test_score  std_train_score  \n",
       "2305    0.000000e+00        0.009147         0.009256  \n",
       "2713    0.000000e+00        0.009147         0.000000  \n",
       "2709    0.000000e+00        0.009147         0.000000  \n",
       "2707    0.000000e+00        0.009147         0.000000  \n",
       "2705    7.364122e-03        0.009147         0.000000  \n",
       "2341    7.363897e-03        0.009147         0.009256  \n",
       "2343    7.363897e-03        0.009147         0.009256  \n",
       "2345    0.000000e+00        0.009147         0.009256  \n",
       "2797    0.000000e+00        0.009147         0.000000  \n",
       "2347    0.000000e+00        0.009147         0.009256  \n",
       "2349    0.000000e+00        0.009147         0.009256  \n",
       "2351    0.000000e+00        0.009147         0.009256  \n",
       "2799    0.000000e+00        0.009147         0.000000  \n",
       "2801    0.000000e+00        0.009147         0.000000  \n",
       "2353    0.000000e+00        0.009147         0.009256  \n",
       "2355    0.000000e+00        0.009147         0.009256  \n",
       "2803    0.000000e+00        0.009147         0.000000  \n",
       "2357    0.000000e+00        0.009147         0.009256  \n",
       "2703    0.000000e+00        0.009147         0.000000  \n",
       "2807    0.000000e+00        0.009147         0.000000  \n",
       "2701    0.000000e+00        0.009147         0.000000  \n",
       "2809    0.000000e+00        0.009147         0.000000  \n",
       "2811    7.364010e-03        0.009147         0.000000  \n",
       "2813    7.364010e-03        0.009147         0.000000  \n",
       "2815    0.000000e+00        0.009147         0.000000  \n",
       "2711    0.000000e+00        0.009147         0.000000  \n",
       "2715    0.000000e+00        0.009147         0.000000  \n",
       "2819    0.000000e+00        0.009147         0.000000  \n",
       "2717    0.000000e+00        0.009147         0.000000  \n",
       "2749    0.000000e+00        0.009147         0.000000  \n",
       "...              ...             ...              ...  \n",
       "1962    1.123916e-07        0.024421         0.007886  \n",
       "1964    4.703589e-04        0.024421         0.007886  \n",
       "1968    2.247832e-07        0.024421         0.007886  \n",
       "1970    2.973602e-07        0.024421         0.007886  \n",
       "8       0.000000e+00        0.030870         0.018122  \n",
       "6       0.000000e+00        0.030870         0.018122  \n",
       "2880    0.000000e+00        0.020840         0.013912  \n",
       "2885    0.000000e+00        0.020840         0.013912  \n",
       "2884    0.000000e+00        0.020840         0.013912  \n",
       "2883    0.000000e+00        0.020840         0.013912  \n",
       "2882    0.000000e+00        0.020840         0.013912  \n",
       "2881    0.000000e+00        0.020840         0.013912  \n",
       "2872    0.000000e+00        0.020840         0.013912  \n",
       "2870    0.000000e+00        0.020840         0.013912  \n",
       "2868    0.000000e+00        0.020840         0.013912  \n",
       "2873    0.000000e+00        0.020840         0.013912  \n",
       "2871    0.000000e+00        0.020840         0.013912  \n",
       "2869    0.000000e+00        0.020840         0.013912  \n",
       "2890    0.000000e+00        0.019478         0.013912  \n",
       "2889    0.000000e+00        0.019478         0.013912  \n",
       "2888    0.000000e+00        0.019478         0.013912  \n",
       "2887    0.000000e+00        0.019478         0.013912  \n",
       "2886    0.000000e+00        0.019478         0.013912  \n",
       "2875    0.000000e+00        0.019478         0.013912  \n",
       "2876    0.000000e+00        0.019478         0.013912  \n",
       "2874    0.000000e+00        0.019478         0.013912  \n",
       "2879    0.000000e+00        0.019478         0.013912  \n",
       "2878    0.000000e+00        0.019478         0.013912  \n",
       "2877    0.000000e+00        0.019478         0.013912  \n",
       "2891    0.000000e+00        0.019478         0.013912  \n",
       "\n",
       "[2892 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T15:32:28.452525Z",
     "start_time": "2019-02-14T15:32:28.447538Z"
    }
   },
   "source": [
    "# Custom GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T17:10:38.913180Z",
     "start_time": "2019-02-14T17:10:38.908193Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from collections import Mapping, namedtuple, defaultdict, Sequence, Iterable\n",
    "from functools import partial, reduce\n",
    "from itertools import product\n",
    "import operator\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from sklearn.base import BaseEstimator, is_classifier, clone\n",
    "from sklearn.base import MetaEstimatorMixin\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection._split import check_cv\n",
    "from sklearn.model_selection._validation import _fit_and_score, _aggregate_score_dicts, _score\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.externals.joblib import Parallel, delayed, logger\n",
    "from sklearn.externals import six\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.fixes import sp_version\n",
    "from sklearn.utils.fixes import MaskedArray\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "from sklearn.utils.validation import indexable, check_is_fitted, _is_arraylike, _num_samples\n",
    "from sklearn.utils.metaestimators import if_delegate_has_method, _safe_split\n",
    "from sklearn.utils.deprecation import DeprecationDict\n",
    "from sklearn.metrics.scorer import _check_multimetric_scoring\n",
    "from sklearn.metrics.scorer import check_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T17:10:40.543167Z",
     "start_time": "2019-02-14T17:10:40.524187Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_fit_and_score(estimator, X, y, scorer, train, test, verbose,\n",
    "                   parameters, fit_params, return_train_score=False,\n",
    "                   return_parameters=False, return_n_test_samples=False,\n",
    "                   return_times=False, return_estimator=False,\n",
    "                   error_score='raise-deprecating'):\n",
    "    \"\"\"Fit estimator and compute scores for a given dataset split.\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator object implementing 'fit'\n",
    "        The object to use to fit the data.\n",
    "    X : array-like of shape at least 2D\n",
    "        The data to fit.\n",
    "    y : array-like, optional, default: None\n",
    "        The target variable to try to predict in the case of\n",
    "        supervised learning.\n",
    "    scorer : A single callable or dict mapping scorer name to the callable\n",
    "        If it is a single callable, the return value for ``train_scores`` and\n",
    "        ``test_scores`` is a single float.\n",
    "        For a dict, it should be one mapping the scorer name to the scorer\n",
    "        callable object / function.\n",
    "        The callable object / fn should have signature\n",
    "        ``scorer(estimator, X, y)``.\n",
    "    train : array-like, shape (n_train_samples,)\n",
    "        Indices of training samples.\n",
    "    test : array-like, shape (n_test_samples,)\n",
    "        Indices of test samples.\n",
    "    verbose : integer\n",
    "        The verbosity level.\n",
    "    error_score : 'raise' | 'raise-deprecating' or numeric\n",
    "        Value to assign to the score if an error occurs in estimator fitting.\n",
    "        If set to 'raise', the error is raised.\n",
    "        If set to 'raise-deprecating', a FutureWarning is printed before the\n",
    "        error is raised.\n",
    "        If a numeric value is given, FitFailedWarning is raised. This parameter\n",
    "        does not affect the refit step, which will always raise the error.\n",
    "        Default is 'raise-deprecating' but from version 0.22 it will change\n",
    "        to np.nan.\n",
    "    parameters : dict or None\n",
    "        Parameters to be set on the estimator.\n",
    "    fit_params : dict or None\n",
    "        Parameters that will be passed to ``estimator.fit``.\n",
    "    return_train_score : boolean, optional, default: False\n",
    "        Compute and return score on training set.\n",
    "    return_parameters : boolean, optional, default: False\n",
    "        Return parameters that has been used for the estimator.\n",
    "    return_n_test_samples : boolean, optional, default: False\n",
    "        Whether to return the ``n_test_samples``\n",
    "    return_times : boolean, optional, default: False\n",
    "        Whether to return the fit/score times.\n",
    "    return_estimator : boolean, optional, default: False\n",
    "        Whether to return the fitted estimator.\n",
    "    Returns\n",
    "    -------\n",
    "    train_scores : dict of scorer name -> float, optional\n",
    "        Score on training set (for all the scorers),\n",
    "        returned only if `return_train_score` is `True`.\n",
    "    test_scores : dict of scorer name -> float, optional\n",
    "        Score on testing set (for all the scorers).\n",
    "    n_test_samples : int\n",
    "        Number of test samples.\n",
    "    fit_time : float\n",
    "        Time spent for fitting in seconds.\n",
    "    score_time : float\n",
    "        Time spent for scoring in seconds.\n",
    "    parameters : dict or None, optional\n",
    "        The parameters that have been evaluated.\n",
    "    estimator : estimator object\n",
    "        The fitted estimator\n",
    "    \"\"\"\n",
    "    if verbose > 1:\n",
    "        if parameters is None:\n",
    "            msg = ''\n",
    "        else:\n",
    "            msg = '%s' % (', '.join('%s=%s' % (k, v)\n",
    "                          for k, v in parameters.items()))\n",
    "        print(\"[CV] %s %s\" % (msg, (64 - len(msg)) * '.'))\n",
    "\n",
    "    # Adjust length of sample weights\n",
    "    fit_params = fit_params if fit_params is not None else {}\n",
    "    fit_params = dict([(k, _index_param_value(X, v, train))\n",
    "                      for k, v in fit_params.items()])\n",
    "\n",
    "    train_scores = {}\n",
    "    if parameters is not None:\n",
    "        estimator.set_params(**parameters)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    X_train, y_train = _safe_split(estimator, X, y, train)\n",
    "    X_test, y_test = _safe_split(estimator, X, y, test, train)\n",
    "\n",
    "    is_multimetric = not callable(scorer)\n",
    "    n_scorers = len(scorer.keys()) if is_multimetric else 1\n",
    "\n",
    "    try:\n",
    "        if y_train is None:\n",
    "            estimator.fit(X_train, **fit_params)\n",
    "        else:\n",
    "            estimator.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Note fit time as time until error\n",
    "        fit_time = time.time() - start_time\n",
    "        score_time = 0.0\n",
    "        if error_score == 'raise':\n",
    "            raise\n",
    "        elif error_score == 'raise-deprecating':\n",
    "            warnings.warn(\"From version 0.22, errors during fit will result \"\n",
    "                          \"in a cross validation score of NaN by default. Use \"\n",
    "                          \"error_score='raise' if you want an exception \"\n",
    "                          \"raised or error_score=np.nan to adopt the \"\n",
    "                          \"behavior from version 0.22.\",\n",
    "                          FutureWarning)\n",
    "            raise\n",
    "        elif isinstance(error_score, numbers.Number):\n",
    "            if is_multimetric:\n",
    "                test_scores = dict(zip(scorer.keys(),\n",
    "                                   [error_score, ] * n_scorers))\n",
    "                if return_train_score:\n",
    "                    train_scores = dict(zip(scorer.keys(),\n",
    "                                        [error_score, ] * n_scorers))\n",
    "            else:\n",
    "                test_scores = error_score\n",
    "                if return_train_score:\n",
    "                    train_scores = error_score\n",
    "            warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
    "                          \" partition for these parameters will be set to %f. \"\n",
    "                          \"Details: \\n%s\" %\n",
    "                          (error_score, format_exception_only(type(e), e)[0]),\n",
    "                          FitFailedWarning)\n",
    "        else:\n",
    "            raise ValueError(\"error_score must be the string 'raise' or a\"\n",
    "                             \" numeric value. (Hint: if using 'raise', please\"\n",
    "                             \" make sure that it has been spelled correctly.)\")\n",
    "\n",
    "    else:\n",
    "        fit_time = time.time() - start_time\n",
    "        # _score will return dict if is_multimetric is True\n",
    "        test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n",
    "        score_time = time.time() - start_time - fit_time\n",
    "        if return_train_score:\n",
    "            train_scores = _score(estimator, X_train, y_train, scorer,\n",
    "                                  is_multimetric)\n",
    "\n",
    "    if verbose > 2:\n",
    "        if is_multimetric:\n",
    "            for scorer_name, score in test_scores.items():\n",
    "                msg += \", %s=%s\" % (scorer_name, score)\n",
    "        else:\n",
    "            msg += \", score=%s\" % test_scores\n",
    "    if verbose > 1:\n",
    "        total_time = score_time + fit_time\n",
    "        end_msg = \"%s, total=%s\" % (msg, logger.short_format_time(total_time))\n",
    "        print(\"[CV] %s %s\" % ((64 - len(end_msg)) * '.', end_msg))\n",
    "\n",
    "    ret = [train_scores, test_scores] if return_train_score else [test_scores]\n",
    "\n",
    "    if return_n_test_samples:\n",
    "        ret.append(_num_samples(X_test))\n",
    "    if return_times:\n",
    "        ret.extend([fit_time, score_time])\n",
    "    if return_parameters:\n",
    "        ret.append(parameters)\n",
    "    if return_estimator:\n",
    "        ret.append(estimator)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T17:10:43.078633Z",
     "start_time": "2019-02-14T17:10:43.053700Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyGridSearchCV(GridSearchCV):\n",
    "\n",
    "    def __init__(self, estimator, param_grid, scoring=None, fit_params=None,\n",
    "                 n_jobs=1, iid='warn', refit=True, cv=None, verbose=0,\n",
    "                 pre_dispatch='2*n_jobs', error_score='raise-deprecating',\n",
    "                 return_train_score=\"warn\"):\n",
    "        super(MyGridSearchCV, self).__init__(\n",
    "            estimator=estimator, param_grid = param_grid, scoring=scoring, fit_params=fit_params,\n",
    "            n_jobs=n_jobs, iid=iid, refit=refit, cv=cv, verbose=verbose,\n",
    "            pre_dispatch=pre_dispatch, error_score=error_score,\n",
    "            return_train_score=return_train_score)\n",
    "\n",
    "    def _get_param_iterator(self):\n",
    "        \"\"\"Return ParameterGrid instance for the given param_grid\"\"\"\n",
    "        return ParameterGrid(self.param_grid)\n",
    "    \n",
    "    def fit(self, X, y=None, groups=None, **fit_params):\n",
    "        \"\"\"Run fit with all sets of parameters.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            Training vector, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
    "            Target relative to X for classification or regression;\n",
    "            None for unsupervised learning.\n",
    "        groups : array-like, with shape (n_samples,), optional\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        **fit_params : dict of string -> object\n",
    "            Parameters passed to the ``fit`` method of the estimator\n",
    "        \"\"\"\n",
    "\n",
    "        if self.fit_params is not None:\n",
    "            warnings.warn('\"fit_params\" as a constructor argument was '\n",
    "                          'deprecated in version 0.19 and will be removed '\n",
    "                          'in version 0.21. Pass fit parameters to the '\n",
    "                          '\"fit\" method instead.', DeprecationWarning)\n",
    "            if fit_params:\n",
    "                warnings.warn('Ignoring fit_params passed as a constructor '\n",
    "                              'argument in favor of keyword arguments to '\n",
    "                              'the \"fit\" method.', RuntimeWarning)\n",
    "            else:\n",
    "                fit_params = self.fit_params\n",
    "        estimator = self.estimator\n",
    "        cv = check_cv(self.cv, y, classifier=is_classifier(estimator))\n",
    "\n",
    "        scorers, self.multimetric_ = _check_multimetric_scoring(\n",
    "            self.estimator, scoring=self.scoring)\n",
    "\n",
    "        if self.multimetric_:\n",
    "            if self.refit is not False and (\n",
    "                    not isinstance(self.refit, six.string_types) or\n",
    "                    # This will work for both dict / list (tuple)\n",
    "                    self.refit not in scorers):\n",
    "                raise ValueError(\"For multi-metric scoring, the parameter \"\n",
    "                                 \"refit must be set to a scorer key \"\n",
    "                                 \"to refit an estimator with the best \"\n",
    "                                 \"parameter setting on the whole data and \"\n",
    "                                 \"make the best_* attributes \"\n",
    "                                 \"available for that metric. If this is not \"\n",
    "                                 \"needed, refit should be set to False \"\n",
    "                                 \"explicitly. %r was passed.\" % self.refit)\n",
    "            else:\n",
    "                refit_metric = self.refit\n",
    "        else:\n",
    "            refit_metric = 'score'\n",
    "\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_splits = cv.get_n_splits(X, y, groups)\n",
    "\n",
    "        base_estimator = clone(self.estimator)\n",
    "\n",
    "        parallel = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
    "                            pre_dispatch=self.pre_dispatch)\n",
    "\n",
    "        fit_and_score_kwargs = dict(scorer=scorers,\n",
    "                                    fit_params=fit_params,\n",
    "                                    return_train_score=self.return_train_score,\n",
    "                                    return_n_test_samples=True,\n",
    "                                    return_times=True,\n",
    "                                    return_parameters=False,\n",
    "                                    error_score=self.error_score,\n",
    "                                    verbose=self.verbose)\n",
    "        results_container = [{}]\n",
    "        with parallel:\n",
    "            all_candidate_params = []\n",
    "            all_out = []\n",
    "\n",
    "            def evaluate_candidates(candidate_params):\n",
    "                candidate_params = list(candidate_params)\n",
    "                n_candidates = len(candidate_params)\n",
    "\n",
    "                if self.verbose > 0:\n",
    "                    print(\"Fitting {0} folds for each of {1} candidates,\"\n",
    "                          \" totalling {2} fits\".format(\n",
    "                              n_splits, n_candidates, n_candidates * n_splits))\n",
    "\n",
    "                out = parallel(delayed(my_fit_and_score)(clone(base_estimator),\n",
    "                                                       X, y,\n",
    "                                                       train=train, test=test,\n",
    "                                                       parameters=parameters,\n",
    "                                                       **fit_and_score_kwargs)\n",
    "                               for parameters, (train, test) in product(candidate_params, cv.split(X, y, groups)))\n",
    "                \n",
    "                print('-------------')\n",
    "                print(out)\n",
    "                print('-------------')\n",
    "                \n",
    "                all_candidate_params.extend(candidate_params)\n",
    "                all_out.extend(out)\n",
    "\n",
    "                # XXX: When we drop Python 2 support, we can use nonlocal\n",
    "                # instead of results_container\n",
    "                results_container[0] = self._format_results(\n",
    "                    all_candidate_params, scorers, n_splits, all_out)\n",
    "                return results_container[0]\n",
    "\n",
    "            self._run_search(evaluate_candidates)\n",
    "\n",
    "        results = results_container[0]\n",
    "\n",
    "        # For multi-metric evaluation, store the best_index_, best_params_ and\n",
    "        # best_score_ iff refit is one of the scorer names\n",
    "        # In single metric evaluation, refit_metric is \"score\"\n",
    "        if self.refit or not self.multimetric_:\n",
    "            self.best_index_ = results[\"rank_test_%s\" % refit_metric].argmin()\n",
    "            self.best_params_ = results[\"params\"][self.best_index_]\n",
    "            self.best_score_ = results[\"mean_test_%s\" % refit_metric][\n",
    "                self.best_index_]\n",
    "\n",
    "        if self.refit:\n",
    "            self.best_estimator_ = clone(base_estimator).set_params(\n",
    "                **self.best_params_)\n",
    "            refit_start_time = time.time()\n",
    "            if y is not None:\n",
    "                self.best_estimator_.fit(X, y, **fit_params)\n",
    "            else:\n",
    "                self.best_estimator_.fit(X, **fit_params)\n",
    "            refit_end_time = time.time()\n",
    "            self.refit_time_ = refit_end_time - refit_start_time\n",
    "\n",
    "        # Store the only scorer not as a dict for single metric evaluation\n",
    "        self.scorer_ = scorers if self.multimetric_ else scorers['score']\n",
    "\n",
    "        self.cv_results_ = results\n",
    "        self.n_splits_ = n_splits\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _format_results(self, candidate_params, scorers, n_splits, out):\n",
    "        n_candidates = len(candidate_params)\n",
    "\n",
    "        # if one choose to see train score, \"out\" will contain train score info\n",
    "        if self.return_train_score:\n",
    "            (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n",
    "             score_time) = zip(*out)\n",
    "        else:\n",
    "            (test_score_dicts, test_sample_counts, fit_time,\n",
    "             score_time) = zip(*out)\n",
    "\n",
    "        # test_score_dicts and train_score dicts are lists of dictionaries and\n",
    "        # we make them into dict of lists\n",
    "        test_scores = _aggregate_score_dicts(test_score_dicts)\n",
    "        if self.return_train_score:\n",
    "            train_scores = _aggregate_score_dicts(train_score_dicts)\n",
    "\n",
    "        # TODO: replace by a dict in 0.21\n",
    "        results = (DeprecationDict() if self.return_train_score == 'warn'\n",
    "                   else {})\n",
    "\n",
    "        def _store(key_name, array, weights=None, splits=False, rank=False):\n",
    "            \"\"\"A small helper to store the scores/times to the cv_results_\"\"\"\n",
    "            # When iterated first by splits, then by parameters\n",
    "            # We want `array` to have `n_candidates` rows and `n_splits` cols.\n",
    "            array = np.array(array, dtype=np.float64).reshape(n_candidates,\n",
    "                                                              n_splits)\n",
    "            if splits:\n",
    "                for split_i in range(n_splits):\n",
    "                    # Uses closure to alter the results\n",
    "                    results[\"split%d_%s\"\n",
    "                            % (split_i, key_name)] = array[:, split_i]\n",
    "\n",
    "            array_means = np.average(array, axis=1, weights=weights)\n",
    "            results['mean_%s' % key_name] = array_means\n",
    "            # Weighted std is not directly available in numpy\n",
    "            array_stds = np.sqrt(np.average((array -\n",
    "                                             array_means[:, np.newaxis]) ** 2,\n",
    "                                            axis=1, weights=weights))\n",
    "            results['std_%s' % key_name] = array_stds\n",
    "\n",
    "            if rank:\n",
    "                results[\"rank_%s\" % key_name] = np.asarray(\n",
    "                    rankdata(-array_means, method='min'), dtype=np.int32)\n",
    "\n",
    "        _store('fit_time', fit_time)\n",
    "        _store('score_time', score_time)\n",
    "        # Use one MaskedArray and mask all the places where the param is not\n",
    "        # applicable for that candidate. Use defaultdict as each candidate may\n",
    "        # not contain all the params\n",
    "        param_results = defaultdict(partial(MaskedArray,\n",
    "                                            np.empty(n_candidates,),\n",
    "                                            mask=True,\n",
    "                                            dtype=object))\n",
    "        for cand_i, params in enumerate(candidate_params):\n",
    "            for name, value in params.items():\n",
    "                # An all masked empty array gets created for the key\n",
    "                # `\"param_%s\" % name` at the first occurrence of `name`.\n",
    "                # Setting the value at an index also unmasks that index\n",
    "                param_results[\"param_%s\" % name][cand_i] = value\n",
    "\n",
    "        results.update(param_results)\n",
    "        # Store a list of param dicts at the key 'params'\n",
    "        results['params'] = candidate_params\n",
    "\n",
    "        # NOTE test_sample counts (weights) remain the same for all candidates\n",
    "        test_sample_counts = np.array(test_sample_counts[:n_splits],\n",
    "                                      dtype=np.int)\n",
    "        iid = self.iid\n",
    "        if self.iid == 'warn':\n",
    "            warn = False\n",
    "            for scorer_name in scorers.keys():\n",
    "                scores = test_scores[scorer_name].reshape(n_candidates,\n",
    "                                                          n_splits)\n",
    "                means_weighted = np.average(scores, axis=1,\n",
    "                                            weights=test_sample_counts)\n",
    "                means_unweighted = np.average(scores, axis=1)\n",
    "                if not np.allclose(means_weighted, means_unweighted,\n",
    "                                   rtol=1e-4, atol=1e-4):\n",
    "                    warn = True\n",
    "                    break\n",
    "\n",
    "            if warn:\n",
    "                warnings.warn(\"The default of the `iid` parameter will change \"\n",
    "                              \"from True to False in version 0.22 and will be\"\n",
    "                              \" removed in 0.24. This will change numeric\"\n",
    "                              \" results when test-set sizes are unequal.\",\n",
    "                              DeprecationWarning)\n",
    "            iid = True\n",
    "\n",
    "        for scorer_name in scorers.keys():\n",
    "            # Computed the (weighted) mean and std for test scores alone\n",
    "            _store('test_%s' % scorer_name, test_scores[scorer_name],\n",
    "                   splits=True, rank=True,\n",
    "                   weights=test_sample_counts if iid else None)\n",
    "            if self.return_train_score:\n",
    "                prev_keys = set(results.keys())\n",
    "                _store('train_%s' % scorer_name, train_scores[scorer_name],\n",
    "                       splits=True)\n",
    "                if self.return_train_score == 'warn':\n",
    "                    for key in set(results.keys()) - prev_keys:\n",
    "                        message = (\n",
    "                            'You are accessing a training score ({!r}), '\n",
    "                            'which will not be available by default '\n",
    "                            'any more in 0.21. If you need training scores, '\n",
    "                            'please set return_train_score=True').format(key)\n",
    "                        # warn on key access\n",
    "                        results.add_warning(key, message, FutureWarning)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T17:10:48.850760Z",
     "start_time": "2019-02-14T17:10:46.901639Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "[[{'score': -2.6507928783382795}, {'score': -9.531124852071002}, 169, 0.031244754791259766, 0.0], [{'score': -2.0629370919881307}, {'score': -32.61000118343197}, 169, 0.031241893768310547, 0.0], [{'score': -1.2371855029585797}, {'score': -48.93207797619047}, 168, 0.031244754791259766, 0.0], [{'score': -2.1451264094955493}, {'score': -10.620964497041422}, 169, 0.031241893768310547, 0.0], [{'score': -1.8595611275964392}, {'score': -35.42857337278106}, 169, 0.031241893768310547, 0.0], [{'score': -1.3862576923076917}, {'score': -48.08989285714285}, 168, 0.031241893768310547, 0.0], [{'score': -1.9374744807121669}, {'score': -11.596113609467455}, 169, 0.031241893768310547, 0.0], [{'score': -1.3542824925816022}, {'score': -34.711149704142024}, 169, 0.015620231628417969, 0.0], [{'score': -1.2533618343195267}, {'score': -47.28721726190476}, 168, 0.034368276596069336, 0.0], [{'score': -2.7131370919881306}, {'score': -11.821550887573965}, 169, 0.01874232292175293, 0.0], [{'score': -1.5350433234421366}, {'score': -40.02206449704142}, 169, 0.034368276596069336, 0.0], [{'score': -1.3665381656804738}, {'score': -48.06756607142857}, 168, 0.015625953674316406, 0.0], [{'score': -2.5752243323442134}, {'score': -11.401205325443783}, 169, 0.015625953674316406, 0.0], [{'score': -1.7405044510385759}, {'score': -30.079994082840237}, 169, 0.031247377395629883, 0.0], [{'score': -1.312864201183432}, {'score': -51.712975}, 168, 0.015621423721313477, 0.0], [{'score': -2.7476958456973284}, {'score': -10.18117928994083}, 169, 0.015621423721313477, 0.0], [{'score': -1.9197833827893171}, {'score': -28.10263076923078}, 169, 0.015621423721313477, 0.0], [{'score': -1.2428831360946742}, {'score': -51.484642857142845}, 168, 0.03124380111694336, 0.0], [{'score': -2.275093175074184}, {'score': -8.85069556213018}, 169, 0.04686379432678223, 0.0], [{'score': -1.2849813056379824}, {'score': -32.616319082840235}, 169, 0.04686379432678223, 0.0], [{'score': -1.1502541420118355}, {'score': -46.51660044642858}, 168, 0.04686379432678223, 0.0], [{'score': -2.0845149109792285}, {'score': -10.149540680473368}, 169, 0.04686379432678223, 0.0], [{'score': -1.379330860534125}, {'score': -33.480016124260366}, 169, 0.04686307907104492, 0.0], [{'score': -1.1264592455621303}, {'score': -52.11311919642857}, 168, 0.04686307907104492, 0.0], [{'score': -1.8431537833827891}, {'score': -10.915537721893491}, 169, 0.04686307907104492, 0.0], [{'score': -1.3472293768545993}, {'score': -33.98645428994084}, 169, 0.046864986419677734, 0.0], [{'score': -0.9941368343195268}, {'score': -49.16846101190477}, 168, 0.046864986419677734, 0.0], [{'score': -1.8899581602373894}, {'score': -9.00827840236686}, 169, 0.046864986419677734, 0.0], [{'score': -1.325004451038576}, {'score': -31.39248964497042}, 169, 0.04686379432678223, 0.0], [{'score': -1.053342381656805}, {'score': -46.143478571428574}, 168, 0.04686379432678223, 0.0], [{'score': -1.9682528189910975}, {'score': -11.708711390532546}, 169, 0.062485694885253906, 0.0], [{'score': -1.708666394658754}, {'score': -30.26936405325444}, 169, 0.031242847442626953, 0.015620946884155273], [{'score': -1.0962698224852077}, {'score': -46.30118229166668}, 168, 0.04686450958251953, 0.0], [{'score': -1.6367781899109792}, {'score': -9.182315384615386}, 169, 0.031243324279785156, 0.015621185302734375], [{'score': -1.2774631305637982}, {'score': -36.002175295857995}, 169, 0.04686450958251953, 0.0], [{'score': -0.9818551035502963}, {'score': -46.24462723214286}, 168, 0.04686450958251953, 0.0], [{'score': -10.804804144658487}, {'score': -10.353680971632095}, 169, 0.015621185302734375, 0.0], [{'score': -7.915104099454582}, {'score': -48.613174937404736}, 169, 0.015621185302734375, 0.0], [{'score': -6.704693644889471}, {'score': -52.776700700626236}, 168, 0.015621185302734375, 0.0], [{'score': -10.652147894031728}, {'score': -9.141807798640654}, 169, 0.016674280166625977, 0.0], [{'score': -7.218923535188008}, {'score': -39.98757825040574}, 169, 0.016674280166625977, 0.0], [{'score': -6.29466573409699}, {'score': -57.63011965805273}, 168, 0.016674280166625977, 0.0], [{'score': -10.718334405643887}, {'score': -10.43657613439783}, 169, 0.0, 0.015625], [{'score': -7.020613035051691}, {'score': -37.237071612913205}, 169, 0.015625, 0.0], [{'score': -5.9629160110690735}, {'score': -48.128148962736255}, 168, 0.015625, 0.0], [{'score': -9.540283148406806}, {'score': -9.036212771069701}, 169, 0.015622138977050781, 0.0], [{'score': -7.003040615216534}, {'score': -45.938198246540686}, 169, 0.0, 0.0], [{'score': -5.843656036876688}, {'score': -57.30427079221941}, 168, 0.01562190055847168, 0.0], [{'score': -10.619496968296751}, {'score': -9.006027858204408}, 169, 0.015622138977050781, 0.0], [{'score': -8.063434564063952}, {'score': -45.45933271392453}, 169, 0.01562190055847168, 0.0], [{'score': -5.626480191494297}, {'score': -58.46476891348446}, 168, 0.015622138977050781, 0.0], [{'score': -10.290997641877903}, {'score': -9.504029153129807}, 169, 0.01562190055847168, 0.015621662139892578], [{'score': -7.775511193624468}, {'score': -44.58704243807328}, 169, 0.01562190055847168, 0.0], [{'score': -6.130985367038244}, {'score': -51.44230712132743}, 168, 0.015621662139892578, 0.0], [{'score': -10.293776587721139}, {'score': -9.329219668347667}, 169, 0.031243562698364258, 0.0], [{'score': -6.363141508882191}, {'score': -39.82445535218128}, 169, 0.0361785888671875, 0.0019943714141845703], [{'score': -5.612131515151436}, {'score': -57.70065631448432}, 168, 0.031243562698364258, 0.0], [{'score': -10.176337504819141}, {'score': -10.481258579626909}, 169, 0.03124260902404785, 0.0029418468475341797], [{'score': -6.208023908119854}, {'score': -37.87993833812417}, 169, 0.03124237060546875, 0.0], [{'score': -5.475744170441072}, {'score': -55.40203931577699}, 168, 0.046150922775268555, 0.0019948482513427734], [{'score': -9.742232156431061}, {'score': -8.527410439651577}, 169, 0.03124237060546875, 0.0], [{'score': -6.238931192864036}, {'score': -42.03005687062455}, 169, 0.04415583610534668, 0.001995086669921875], [{'score': -5.6730846323643975}, {'score': -57.80964805114815}, 168, 0.031241655349731445, 0.0], [{'score': -9.505788254762434}, {'score': -8.982441601092768}, 169, 0.029018163681030273, 0.0019943714141845703], [{'score': -6.972525675343923}, {'score': -39.12555480549744}, 169, 0.031241655349731445, 0.0], [{'score': -5.785385783152225}, {'score': -53.124636124691584}, 168, 0.03850841522216797, 0.001995086669921875], [{'score': -10.081622047721678}, {'score': -8.954893441800492}, 169, 0.0361785888671875, 0.0009970664978027344], [{'score': -6.6528826917464245}, {'score': -41.47302206389831}, 169, 0.030015230178833008, 0.0019941329956054688], [{'score': -5.786373158861894}, {'score': -50.60359983207201}, 168, 0.03124260902404785, 0.003939628601074219], [{'score': -9.191355168688256}, {'score': -10.721603193743364}, 169, 0.027024030685424805, 0.0009968280792236328], [{'score': -7.905993736117097}, {'score': -43.73139663604092}, 169, 0.03101325035095215, 0.0019936561584472656], [{'score': -5.43832718907829}, {'score': -52.34986935355094}, 168, 0.02499556541442871, 0.0], [{'score': -22.87997383312735}, {'score': -16.64214997747804}, 169, 0.006083250045776367, 0.0], [{'score': -15.06602213605366}, {'score': -67.27428013627888}, 169, 0.007977724075317383, 0.000997304916381836], [{'score': -14.659198462441113}, {'score': -68.16482829867971}, 168, 0.0059833526611328125, 0.0019958019256591797], [{'score': -22.87997383312735}, {'score': -16.46374775676133}, 169, 0.004987001419067383, 0.0], [{'score': -15.066022136053663}, {'score': -68.91369777832017}, 169, 0.004985332489013672, 0.0], [{'score': -14.659198462441113}, {'score': -68.1430369936733}, 168, 0.004986286163330078, 0.0], [{'score': -22.87997383312735}, {'score': -16.584441014610952}, 169, 0.0049855709075927734, 0.0], [{'score': -15.066022136053663}, {'score': -67.45700571730777}, 169, 0.00498652458190918, 0.0009975433349609375], [{'score': -14.659198462441113}, {'score': -68.16482829867971}, 168, 0.004988431930541992, 0.0009958744049072266], [{'score': -22.87997383312735}, {'score': -16.521456719628414}, 169, 0.0020570755004882812, 0.0], [{'score': -15.066022136053663}, {'score': -67.60307376051706}, 169, 0.005983591079711914, 0.0], [{'score': -14.659198462441113}, {'score': -68.16482829867971}, 168, 0.004988193511962891, 0.0], [{'score': -22.87997383312735}, {'score': -16.584441014610952}, 169, 0.00498652458190918, 0.0], [{'score': -15.06602213605366}, {'score': -68.2014179341638}, 169, 0.003054380416870117, 0.0], [{'score': -14.659198462441113}, {'score': -68.16482829867971}, 168, 0.0, 0.0], [{'score': -22.87997383312735}, {'score': -16.873532228602915}, 169, 0.015621662139892578, 0.0], [{'score': -15.066022136053663}, {'score': -67.74427179199357}, 169, 0.004987001419067383, 0.0], [{'score': -14.659198462441113}, {'score': -68.16482829867971}, 168, 0.0049860477447509766, 0.000997781753540039], [{'score': -8.887518903871833}, {'score': -10.133029970365579}, 169, 0.0070438385009765625, 0.0], [{'score': -6.495934011951402}, {'score': -41.79997800919022}, 169, 0.015621662139892578, 0.0], [{'score': -5.662126910549219}, {'score': -55.81022996615319}, 168, 0.0, 0.0], [{'score': -8.887518903871833}, {'score': -11.386529158829214}, 169, 0.015622377395629883, 0.0], [{'score': -6.495934011951404}, {'score': -41.290696418730086}, 169, 0.009973526000976562, 0.0], [{'score': -5.66212691054922}, {'score': -55.78674926385444}, 168, 0.0, 0.0], [{'score': -8.887518903871833}, {'score': -10.107981848356136}, 169, 0.015621662139892578, 0.0], [{'score': -6.495934011951403}, {'score': -40.92193666127456}, 169, 0.0, 0.0], [{'score': -5.66212691054922}, {'score': -55.8102299661532}, 168, 0.0, 0.0], [{'score': -8.887518903871833}, {'score': -10.469623195355934}, 169, 0.015620231628417969, 0.0], [{'score': -6.495934011951403}, {'score': -41.265768031898475}, 169, 0.003054380416870117, 0.0], [{'score': -5.662126910549219}, {'score': -55.8102299661532}, 168, 0.015621662139892578, 0.0], [{'score': -8.887518903871833}, {'score': -11.280451017477903}, 169, 0.0, 0.0], [{'score': -6.495934011951404}, {'score': -41.54655033908539}, 169, 0.015622377395629883, 0.0], [{'score': -5.66212691054922}, {'score': -55.81022996615319}, 168, 0.0, 0.0], [{'score': -8.887518903871833}, {'score': -10.450335002323103}, 169, 0.015620231628417969, 0.0], [{'score': -6.495934011951403}, {'score': -41.35858610412068}, 169, 0.0, 0.0], [{'score': -5.662126910549219}, {'score': -55.81022996615319}, 168, 0.015621662139892578, 0.0]]\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:    1.8s finished\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:238: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyGridSearchCV(cv=None, error_score='raise-deprecating',\n",
       "        estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', PipelineHelper(available_models={'std': StandardScaler(copy=True, with_mean=True, with_std=True), 'max': MaxAbsScaler(copy=True)},\n",
       "        include_bypass=True, selected_model=None)), ('regressor', PipelineHelper(available_models={'rf': RandomForestRegressor(bootstrap=True, criterio...on_fraction=0.1, verbose=0, warm_start=False)},\n",
       "        include_bypass=False, selected_model=None))]),\n",
       "        fit_params=None, iid='warn', n_jobs=-1,\n",
       "        param_grid={'scaler__selected_model': [('std', {'with_mean': True, 'with_std': True}), ('std', {'with_mean': True, 'with_std': False}), ('std', {'with_mean': False, 'with_std': True}), ('std', {'with_mean': False, 'with_std': False}), ('max', {}), (None, {}, True)], 'regressor__selected_model': [('rf', {'n_estimators': 10}), ('rf', {'n_estimators': 20}), ('ada', {'n_estimators': 10}), ('ada', {'n_estimators': 20}), ('gb', {'n_estimators': 10}), ('gb', {'n_estimators': 20})]},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "        scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = MyGridSearchCV(pipe, params, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1, return_train_score=True)\n",
    "grid.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "74px",
    "width": "166px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
